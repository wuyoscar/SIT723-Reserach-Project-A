
@article{wilson_polarization_2020,
	title = {Polarization in the contemporary political and media landscape},
	volume = {34},
	issn = {23521546},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352154620301078},
	doi = {10.1016/j.cobeha.2020.07.005},
	language = {en},
	urldate = {2021-11-21},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Wilson, Anne E and Parker, Victoria A and Feinberg, Matthew},
	month = aug,
	year = {2020},
	pages = {223--228},
	file = {Wilson et al. - 2020 - Polarization in the contemporary political and med.pdf:files/171/Wilson et al. - 2020 - Polarization in the contemporary political and med.pdf:application/pdf},
}

@article{shultziner_distorting_2021,
	title = {Distorting the {News}? {The} {Mechanisms} of {Partisan} {Media} {Bias} and {Its} {Effects} on {News} {Production}},
	volume = {43},
	issn = {0190-9320, 1573-6687},
	shorttitle = {Distorting the {News}?},
	url = {http://link.springer.com/10.1007/s11109-019-09551-y},
	doi = {10.1007/s11109-019-09551-y},
	abstract = {Integrating scholarship from several fields of study, this paper proposes a new model for understanding how partisan bias operates and how to measure its effects. We chart the factors that influence partisan bias over news production within news organizations that are simultaneously constrained and conditioned by factors of market competition, context considerations and journalistic norms. We argue that partisan media bias of a news-story is expressed in the manner that different news outlets cover the same political story within the same timeframe relative to one another. We find that description bias is a key parameter that is intertwined with selection bias mechanisms that highlight and downplay news items according to their content. We illustrate how partisan media coverage occurs in the context of a major political protest in Israel. We employ a dataset consisting of 1556 news products from all major newspapers. We find that partisan bias finds its strongest expression in the types of news products that the news outlets emphasize on their front-page and in the sizing of articles. These mechanisms of partisan bias can be generalized in the study of partisan bias in other types of news outlets.},
	language = {en},
	number = {1},
	urldate = {2021-11-21},
	journal = {Political Behavior},
	author = {Shultziner, Doron and Stukalin, Yelena},
	month = mar,
	year = {2021},
	pages = {201--222},
	file = {Shultziner and Stukalin - 2021 - Distorting the News The Mechanisms of Partisan Me.pdf:files/172/Shultziner and Stukalin - 2021 - Distorting the News The Mechanisms of Partisan Me.pdf:application/pdf},
}

@article{brandtzaeg_trust_2017,
	title = {Trust and distrust in online fact-checking services},
	volume = {60},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3122803},
	doi = {10.1145/3122803},
	abstract = {Even when checked by fact checkers, facts are often still open to preexisting bias and doubt.},
	language = {en},
	number = {9},
	urldate = {2021-11-21},
	journal = {Communications of the ACM},
	author = {Brandtzaeg, Petter Bae and Følstad, Asbjørn},
	month = aug,
	year = {2017},
	pages = {65--71},
	file = {Brandtzaeg and Følstad - 2017 - Trust and distrust in online fact-checking service.pdf:files/173/Brandtzaeg and Følstad - 2017 - Trust and distrust in online fact-checking service.pdf:application/pdf},
}

@techreport{estiri_objective_2021,
	type = {preprint},
	title = {An {Objective} {Search} for {Unrecognized} {Bias} in {Validated} {COVID}-19 {Prediction} {Models}},
	url = {http://medrxiv.org/lookup/doi/10.1101/2021.10.28.21265629},
	abstract = {ABSTRACT
          The growing recognition of algorithmic bias has spurred discussions about fairness in artificial intelligence (AI) / machine learning (ML) algorithms. The increasing translation of predictive models into clinical practice brings an increased risk of direct harm from algorithmic bias; however, bias remains incompletely measured in many medical AI applications. Using data from over 56 thousand Mass General Brigham (MGB) patients with confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), we evaluate unrecognized bias in four AI models developed during the early months of the pandemic in Boston, Massachusetts that predict risks of hospital admission, ICU admission, mechanical ventilation, and death after a SARS-CoV-2 infection purely based on their pre-infection longitudinal medical records.
          We discuss that while a model can be biased against certain protected groups (i.e., perform worse) in certain tasks, it can be at the same time biased towards another protected group (i.e., perform better). As such, current bias evaluation studies may lack a full depiction of the variable effects of a model on its subpopulations.
          If the goal is to make a change in a positive way, the underlying roots of bias need to be fully explored in medical AI. Only a holistic evaluation, a diligent search for unrecognized bias, can provide enough information for an unbiased judgment of AI bias that can invigorate follow-up investigations on identifying the underlying roots of bias and ultimately make a change.},
	language = {en},
	urldate = {2021-11-21},
	institution = {Health Informatics},
	author = {Estiri, Hossein and Strasser, Zachary H and Rashidian, Sina and Klann, Jeffery G and Wagholikar, Kavishwar B and McCoy, Thomas H and Murphy, Shawn N},
	month = oct,
	year = {2021},
	doi = {10.1101/2021.10.28.21265629},
	file = {Estiri et al. - 2021 - An Objective Search for Unrecognized Bias in Valid.pdf:files/174/Estiri et al. - 2021 - An Objective Search for Unrecognized Bias in Valid.pdf:application/pdf},
}

@article{guo_application_2021,
	title = {The application of artificial intelligence and data integration in {COVID}-19 studies: a scoping review},
	volume = {28},
	issn = {1527-974X},
	shorttitle = {The application of artificial intelligence and data integration in {COVID}-19 studies},
	url = {https://academic.oup.com/jamia/article/28/9/2050/6307183},
	doi = {10.1093/jamia/ocab098},
	abstract = {Objective: To summarize how artiﬁcial intelligence (AI) is being applied in COVID-19 research and determine whether these AI applications integrated heterogenous data from different sources for modeling. Materials and Methods: We searched 2 major COVID-19 literature databases, the National Institutes of Health’s LitCovid and the World Health Organization’s COVID-19 database on March 9, 2021. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guideline, 2 reviewers independently reviewed all the articles in 2 rounds of screening.
Results: In the 794 studies included in the ﬁnal qualitative analysis, we identiﬁed 7 key COVID-19 research areas in which AI was applied, including disease forecasting, medical imaging-based diagnosis and prognosis, early detection and prognosis (non-imaging), drug repurposing and early drug discovery, social media data analysis, genomic, transcriptomic, and proteomic data analysis, and other COVID-19 research topics. We also found that there was a lack of heterogenous data integration in these AI applications. Discussion: Risk factors relevant to COVID-19 outcomes exist in heterogeneous data sources, including electronic health records, surveillance systems, sociodemographic datasets, and many more. However, most AI applications in COVID-19 research adopted a single-sourced approach that could omit important risk factors and thus lead to biased algorithms. Integrating heterogeneous data for modeling will help realize the full potential of AI algorithms, improve precision, and reduce bias.
Conclusion: There is a lack of data integration in the AI applications in COVID-19 research and a need for a multilevel AI framework that supports the analysis of heterogeneous data from different sources.},
	language = {en},
	number = {9},
	urldate = {2021-11-21},
	journal = {Journal of the American Medical Informatics Association},
	author = {Guo, Yi and Zhang, Yahan and Lyu, Tianchen and Prosperi, Mattia and Wang, Fei and Xu, Hua and Bian, Jiang},
	month = aug,
	year = {2021},
	pages = {2050--2067},
	file = {Guo et al. - 2021 - The application of artificial intelligence and dat.pdf:files/175/Guo et al. - 2021 - The application of artificial intelligence and dat.pdf:application/pdf},
}

@article{pranesh_looking_2021,
	title = {Looking for {COVID}-19 misinformation in multilingual social media texts},
	url = {http://arxiv.org/abs/2105.03313},
	abstract = {This paper presents the Multilingual COVID-19 Analysis Method (CMTA) for detecting and observing the spread of misinformation about this disease within texts. CMTA proposes a data science (DS) pipeline that applies machine learning models for processing, classifying (Dense-CNN) and analyzing (MBERT) multilingual (micro)-texts. DS pipeline data preparation tasks extract features from multilingual textual data and categorize it into speciﬁc information classes (i.e., ’false’, ’partly false’, ’misleading’). The CMTA pipeline has been experimented with multilingual micro-texts (tweets), showing misinformation spread across diﬀerent languages. To assess the performance of CMTA and put it in perspective, we performed a comparative analysis of CMTA with eight monolingual models used for detecting misinformation. The comparison shows that CMTA has surpassed various monolingual models and suggests that it can be used as a general method for detecting misinformation in multilingual micro-texts. CMTA experimental results show misinformation trends about COVID-19 in diﬀerent languages during the ﬁrst pandemic months.},
	language = {en},
	urldate = {2021-11-21},
	journal = {arXiv:2105.03313 [cs]},
	author = {Pranesh, Raj Ratn and Farokhnejad, Mehrdad and Shekhar, Ambesh and Vargas-Solar, Genoveva},
	month = may,
	year = {2021},
	note = {arXiv: 2105.03313},
	keywords = {Computer Science - Computation and Language, Computer Science - Databases},
	file = {Pranesh et al. - 2021 - Looking for COVID-19 misinformation in multilingua.pdf:files/176/Pranesh et al. - 2021 - Looking for COVID-19 misinformation in multilingua.pdf:application/pdf},
}

@article{hamed_jelodar_deep_2020,
	title = {Deep {Sentiment} {Classification} and {Topic} {Discovery} on {Novel} {Coronavirus} or {COVID}-19 {Online} {Discussions}: {NLP} {Using} {LSTM} {Recurrent} {Neural} {Network} {Approach}},
	volume = {24},
	issn = {2168-2194, 2168-2208},
	shorttitle = {Deep {Sentiment} {Classification} and {Topic} {Discovery} on {Novel} {Coronavirus} or {COVID}-19 {Online} {Discussions}},
	url = {https://ieeexplore.ieee.org/document/9112671/},
	doi = {10.1109/JBHI.2020.3001216},
	abstract = {Internet forums and public social media, such as online healthcare forums, provide a convenient channel for users (people/patients) concerned about health issues to discuss and share information with each other. In late December 2019, an outbreak of a novel coronavirus (infection from which results in the disease named COVID-19) was reported, and, due to the rapid spread of the virus in other parts of the world, the World Health Organization declared a state of emergency. In this paper, we used automated extraction of COVID-19–related discussions from social media and a natural language process (NLP) method based on topic modeling to uncover various issues related to COVID19 from public opinions. Moreover, we also investigate how to use LSTM recurrent neural network for sentiment classiﬁcation of COVID-19 comments. Our ﬁndings shed light on the importance of using public opinions and suitable computational techniques to understand issues surrounding COVID-19 and to guide related decision-making. In addition, experiments demonstrated that the research model achieved an accuracy of 81.15\% – a higher accuracy than that of several other well-known machine-learning algorithms for COVID-19–Sentiment Classiﬁcation.},
	language = {en},
	number = {10},
	urldate = {2021-11-21},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {{Hamed Jelodar} and Wang, Yongli and Orji, Rita and Huang, Shucheng},
	month = oct,
	year = {2020},
	pages = {2733--2742},
	file = {Jelodar et al. - 2020 - Deep Sentiment Classification and Topic Discovery .pdf:files/179/Jelodar et al. - 2020 - Deep Sentiment Classification and Topic Discovery .pdf:application/pdf;Australian_Harvard_2021.ens:files/328/Australian_Harvard_2021.ens:application/octet-stream},
}

@article{yang_covid-19_2021,
	title = {The {COVID}-19 {Infodemic}: {Twitter} versus {Facebook}},
	volume = {8},
	issn = {2053-9517, 2053-9517},
	shorttitle = {The {COVID}-19 {Infodemic}},
	url = {http://journals.sagepub.com/doi/10.1177/20539517211013861},
	doi = {10.1177/20539517211013861},
	abstract = {The global spread of the novel coronavirus is affected by the spread of related misinformation—the so-called COVID-19 Infodemic—that makes populations more vulnerable to the disease through resistance to mitigation efforts. Here, we analyze the prevalence and diffusion of links to low-credibility content about the pandemic across two major social media platforms, Twitter and Facebook. We characterize cross-platform similarities and differences in popular sources, diffusion patterns, influencers, coordination, and automation. Comparing the two platforms, we find divergence among the prevalence of popular low-credibility sources and suspicious videos. A minority of accounts and pages exert a strong influence on each platform. These misinformation “superspreaders” are often associated with the low-credibility sources and tend to be verified by the platforms. On both platforms, there is evidence of coordinated sharing of Infodemic content. The overt nature of this manipulation points to the need for societal-level solutions in addition to mitigation strategies within the platforms. However, we highlight limits imposed by inconsistent data-access policies on our capability to study harmful manipulations of information ecosystems.},
	language = {en},
	number = {1},
	urldate = {2021-11-22},
	journal = {Big Data \& Society},
	author = {Yang, Kai-Cheng and Pierri, Francesco and Hui, Pik-Mai and Axelrod, David and Torres-Lugo, Christopher and Bryden, John and Menczer, Filippo},
	month = jan,
	year = {2021},
	pages = {205395172110138},
	file = {Yang et al. - 2021 - The COVID-19 Infodemic Twitter versus Facebook.pdf:files/194/Yang et al. - 2021 - The COVID-19 Infodemic Twitter versus Facebook.pdf:application/pdf},
}

@article{cinelli_covid-19_2020,
	title = {The {COVID}-19 social media infodemic},
	volume = {10},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-73510-5},
	doi = {10.1038/s41598-020-73510-5},
	abstract = {Abstract
            
              We address the diffusion of information about the COVID-19 with a massive data analysis on Twitter, Instagram, YouTube, Reddit and Gab. We analyze engagement and interest in the COVID-19 topic and provide a differential assessment on the evolution of the discourse on a global scale for each platform and their users. We fit information spreading with epidemic models characterizing the basic reproduction number
              
                
                  \$\$R\_0\$\$
                  
                    
                      R
                      0
                    
                  
                
              
              for each social media platform. Moreover, we identify information spreading from questionable sources, finding different volumes of misinformation in each platform. However, information from both reliable and questionable sources do not present different spreading patterns. Finally, we provide platform-dependent numerical estimates of rumors’ amplification.},
	language = {en},
	number = {1},
	urldate = {2021-11-22},
	journal = {Scientific Reports},
	author = {Cinelli, Matteo and Quattrociocchi, Walter and Galeazzi, Alessandro and Valensise, Carlo Michele and Brugnoli, Emanuele and Schmidt, Ana Lucia and Zola, Paola and Zollo, Fabiana and Scala, Antonio},
	month = dec,
	year = {2020},
	pages = {16598},
	file = {Cinelli et al. - 2020 - The COVID-19 social media infodemic.pdf:files/195/Cinelli et al. - 2020 - The COVID-19 social media infodemic.pdf:application/pdf},
}

@article{pranesh_looking_2021-1,
	title = {Looking for {COVID}-19 misinformation in multilingual social media texts},
	url = {http://arxiv.org/abs/2105.03313},
	abstract = {This paper presents the Multilingual COVID-19 Analysis Method (CMTA) for detecting and observing the spread of misinformation about this disease within texts. CMTA proposes a data science (DS) pipeline that applies machine learning models for processing, classifying (Dense-CNN) and analyzing (MBERT) multilingual (micro)-texts. DS pipeline data preparation tasks extract features from multilingual textual data and categorize it into speciﬁc information classes (i.e., ’false’, ’partly false’, ’misleading’). The CMTA pipeline has been experimented with multilingual micro-texts (tweets), showing misinformation spread across diﬀerent languages. To assess the performance of CMTA and put it in perspective, we performed a comparative analysis of CMTA with eight monolingual models used for detecting misinformation. The comparison shows that CMTA has surpassed various monolingual models and suggests that it can be used as a general method for detecting misinformation in multilingual micro-texts. CMTA experimental results show misinformation trends about COVID-19 in diﬀerent languages during the ﬁrst pandemic months.},
	language = {en},
	urldate = {2021-11-22},
	journal = {arXiv:2105.03313 [cs]},
	author = {Pranesh, Raj Ratn and Farokhnejad, Mehrdad and Shekhar, Ambesh and Vargas-Solar, Genoveva},
	month = may,
	year = {2021},
	note = {arXiv: 2105.03313},
	keywords = {Computer Science - Computation and Language, Computer Science - Databases},
	file = {Pranesh et al. - 2021 - Looking for COVID-19 misinformation in multilingua.pdf:files/202/Pranesh et al. - 2021 - Looking for COVID-19 misinformation in multilingua.pdf:application/pdf},
}

@article{varma_systematic_2021,
	title = {A systematic survey on deep learning and machine learning approaches of fake news detection in the pre- and post-{COVID}-19 pandemic},
	volume = {14},
	issn = {1756-378X},
	url = {https://www.emerald.com/insight/content/doi/10.1108/IJICC-04-2021-0069/full/html},
	doi = {10.1108/IJICC-04-2021-0069},
	abstract = {Purpose – The rapid advancement of technology in online communication and fingertip access to the Internet has resulted in the expedited dissemination of fake news to engage a global audience at a low cost by news channels, freelance reporters and websites. Amid the coronavirus disease 2019 (COVID-19) pandemic, individuals are inflicted with these false and potentially harmful claims and stories, which may harm the vaccination process. Psychological studies reveal that the human ability to detect deception is only slightly better than chance; therefore, there is a growing need for serious consideration for developing automated strategies to combat fake news that traverses these platforms at an alarming rate. This paper systematically reviews the existing fake news detection technologies by exploring various machine learning and deep learning techniques pre- and post-pandemic, which has never been done before to the best of the authors’ knowledge. Design/methodology/approach – The detailed literature review on fake news detection is divided into three major parts. The authors searched papers no later than 2017 on fake news detection approaches on deep learning and machine learning. The papers were initially searched through the Google scholar platform, and they have been scrutinized for quality. The authors kept “Scopus” and “Web of Science” as quality indexing parameters. All research gaps and available databases, data pre-processing, feature extraction techniques and evaluation methods for current fake news detection technologies have been explored, illustrating them using tables, charts and trees. Findings – The paper is dissected into two approaches, namely machine learning and deep learning, to present a better understanding and a clear objective. Next, the authors present a viewpoint on which approach is better and future research trends, issues and challenges for researchers, given the relevance and urgency of a detailed and thorough analysis of existing models. This paper also delves into fake new detection during COVID-19, and it can be inferred that research and modeling are shifting toward the use of ensemble approaches.},
	language = {en},
	number = {4},
	urldate = {2021-11-25},
	journal = {International Journal of Intelligent Computing and Cybernetics},
	author = {Varma, Rajshree and Verma, Yugandhara and Vijayvargiya, Priya and Churi, Prathamesh P.},
	month = oct,
	year = {2021},
	pages = {617--646},
	file = {Varma et al. - 2021 - A systematic survey on deep learning and machine l.pdf:files/204/Varma et al. - 2021 - A systematic survey on deep learning and machine l.pdf:application/pdf},
}

@article{varma_systematic_2021-1,
	title = {A systematic survey on deep learning and machine learning approaches of fake news detection in the pre- and post-{COVID}-19 pandemic},
	volume = {14},
	issn = {1756-378X},
	url = {https://www.emerald.com/insight/content/doi/10.1108/IJICC-04-2021-0069/full/html},
	doi = {10.1108/IJICC-04-2021-0069},
	abstract = {Purpose – The rapid advancement of technology in online communication and fingertip access to the Internet has resulted in the expedited dissemination of fake news to engage a global audience at a low cost by news channels, freelance reporters and websites. Amid the coronavirus disease 2019 (COVID-19) pandemic, individuals are inflicted with these false and potentially harmful claims and stories, which may harm the vaccination process. Psychological studies reveal that the human ability to detect deception is only slightly better than chance; therefore, there is a growing need for serious consideration for developing automated strategies to combat fake news that traverses these platforms at an alarming rate. This paper systematically reviews the existing fake news detection technologies by exploring various machine learning and deep learning techniques pre- and post-pandemic, which has never been done before to the best of the authors’ knowledge. Design/methodology/approach – The detailed literature review on fake news detection is divided into three major parts. The authors searched papers no later than 2017 on fake news detection approaches on deep learning and machine learning. The papers were initially searched through the Google scholar platform, and they have been scrutinized for quality. The authors kept “Scopus” and “Web of Science” as quality indexing parameters. All research gaps and available databases, data pre-processing, feature extraction techniques and evaluation methods for current fake news detection technologies have been explored, illustrating them using tables, charts and trees. Findings – The paper is dissected into two approaches, namely machine learning and deep learning, to present a better understanding and a clear objective. Next, the authors present a viewpoint on which approach is better and future research trends, issues and challenges for researchers, given the relevance and urgency of a detailed and thorough analysis of existing models. This paper also delves into fake new detection during COVID-19, and it can be inferred that research and modeling are shifting toward the use of ensemble approaches.},
	language = {en},
	number = {4},
	urldate = {2021-11-25},
	journal = {International Journal of Intelligent Computing and Cybernetics},
	author = {Varma, Rajshree and Verma, Yugandhara and Vijayvargiya, Priya and Churi, Prathamesh P.},
	month = oct,
	year = {2021},
	pages = {617--646},
	file = {Varma et al. - 2021 - A systematic survey on deep learning and machine l.pdf:files/206/Varma et al. - 2021 - A systematic survey on deep learning and machine l.pdf:application/pdf},
}

@article{hamborg_automated_2019,
	title = {Automated identification of media bias in news articles: an interdisciplinary literature review},
	volume = {20},
	issn = {1432-5012, 1432-1300},
	shorttitle = {Automated identification of media bias in news articles},
	url = {http://link.springer.com/10.1007/s00799-018-0261-y},
	doi = {10.1007/s00799-018-0261-y},
	abstract = {Media bias, i.e., slanted news coverage, can strongly impact the public perception of the reported topics. In the social sciences, research over the past decades has developed comprehensive models to describe media bias and effective, yet often manual and thus cumbersome, methods for analysis. In contrast, in computer science fast, automated, and scalable methods are available, but few approaches systematically analyze media bias. The models used to analyze media bias in computer science tend to be simpler compared to models established in the social sciences, and do not necessarily address the most pressing substantial questions, despite technically superior approaches. Computer science research on media bias thus stands to proﬁt from a closer integration of models for the study of media bias developed in the social sciences with automated methods from computer science. This article ﬁrst establishes a shared conceptual understanding by mapping the state of the art from the social sciences to a framework, which can be targeted by approaches from computer science. Next, we investigate different forms of media bias and review how each form is analyzed in the social sciences. For each form, we then discuss methods from computer science suitable to (semi-)automate the corresponding analysis. Our review suggests that suitable, automated methods from computer science, primarily in the realm of natural language processing, are already available for each of the discussed forms of media bias, opening multiple directions for promising further research in computer science in this area.},
	language = {en},
	number = {4},
	urldate = {2021-11-26},
	journal = {International Journal on Digital Libraries},
	author = {Hamborg, Felix and Donnay, Karsten and Gipp, Bela},
	month = dec,
	year = {2019},
	pages = {391--415},
}

@article{spinde_automated_2021,
	title = {Automated identification of bias inducing words in news articles using linguistic and context-oriented features},
	volume = {58},
	issn = {03064573},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306457321000157},
	doi = {10.1016/j.ipm.2021.102505},
	abstract = {Media has a substantial impact on public perception of events, and, accordingly, the way media presents events can potentially alter the beliefs and views of the public. One of the ways in which bias in news articles can be introduced is by altering word choice. Such a form of bias is very challenging to identify automatically due to the high context-dependence and the lack of a large-scale gold-standard data set. In this paper, we present a prototypical yet robust and diverse data set for media bias research. It consists of 1,700 statements representing various media bias instances and contains labels for media bias identification on the word and sentence level. In contrast to existing research, our data incorporate background information on the participants’ demographics, political ideology, and their opinion about media in general. Based on our data, we also present a way to detect bias-inducing words in news articles automatically. Our approach is feature-oriented, which provides a strong descriptive and explanatory power compared to deep learning techniques. We identify and engineer various linguistic, lexical, and syntactic features that can potentially be media bias indicators. Our resource collection is the most complete within the media bias research area to the best of our knowledge. We evaluate all of our features in various combinations and retrieve their possible importance both for future research and for the task in general. We also evaluate various possible Machine Learning approaches with all of our features. XGBoost, a decision tree implementation, yields the best results. Our approach achieves an 𝐹1-score of 0.43, a precision of 0.29, a recall of 0.77, and a ROC AUC of 0.79, which outperforms current media bias detection methods based on features. We propose future improvements, discuss the perspectives of the feature-based approach and a combination of neural networks and deep learning with our current system.},
	language = {en},
	number = {3},
	urldate = {2021-11-26},
	journal = {Information Processing \& Management},
	author = {Spinde, Timo and Rudnitckaia, Lada and Mitrović, Jelena and Hamborg, Felix and Granitzer, Michael and Gipp, Bela and Donnay, Karsten},
	month = may,
	year = {2021},
	pages = {102505},
	file = {Spinde et al. - 2021 - Automated identification of bias inducing words in.pdf:files/212/Spinde et al. - 2021 - Automated identification of bias inducing words in.pdf:application/pdf},
}

@inproceedings{hamborg_newsmtsc_2021,
	address = {Online},
	title = {{NewsMTSC}: {A} {Dataset} for ({Multi}-){Target}-dependent {Sentiment} {Classification} in {Political} {News} {Articles}},
	shorttitle = {{NewsMTSC}},
	url = {https://aclanthology.org/2021.eacl-main.142},
	doi = {10.18653/v1/2021.eacl-main.142},
	abstract = {Previous research on target-dependent sentiment classiﬁcation (TSC) has mostly focused on reviews, social media, and other domains where authors tend to express sentiment explicitly. In this paper, we investigate TSC in news articles, a much less researched TSC domain despite the importance of news as an essential information source in individual and societal decision making. We introduce NewsMTSC, a high-quality dataset for TSC on news articles with key differences compared to established TSC datasets, including, for example, different means to express sentiment, longer texts, and a second test-set to measure the inﬂuence of multi-target sentences. We also propose a model that uses a BiGRU to interact with multiple embeddings, e.g., from a language model and external knowledge sources. The proposed model improves the performance of the prior state-of-the-art from F 1m = 81.7 to 83.1 (real-world sentiment distribution) and from F 1m = 81.2 to 82.5 (multi-target sentences).},
	language = {en},
	urldate = {2021-11-26},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Hamborg, Felix and Donnay, Karsten},
	year = {2021},
	pages = {1663--1675},
	file = {Hamborg and Donnay - 2021 - NewsMTSC A Dataset for (Multi-)Target-dependent S.pdf:files/213/Hamborg and Donnay - 2021 - NewsMTSC A Dataset for (Multi-)Target-dependent S.pdf:application/pdf},
}

@article{hamborg_towards_2021,
	title = {Towards {Target}-dependent {Sentiment} {Classification} in {News} {Articles}},
	volume = {12646},
	url = {http://arxiv.org/abs/2105.09660},
	doi = {10.1007/978-3-030-71305-8_12},
	abstract = {Extensive research on target-dependent sentiment classiﬁcation (TSC) has led to strong classiﬁcation performances in domains where authors tend to explicitly express sentiment about speciﬁc entities or topics, such as in reviews or on social media. We investigate TSC in news articles, a much less researched domain, despite the importance of news as an essential information source in individual and societal decision making. This article introduces NewsTSC, a manually annotated dataset to explore TSC on news articles. Investigating characteristics of sentiment in news and contrasting them to popular TSC domains, we ﬁnd that sentiment in the news is expressed less explicitly, is more dependent on context and readership, and requires a greater degree of interpretation. In an extensive evaluation, we ﬁnd that the current state-of-the-art in TSC performs worse on news articles than on other domains (average recall AvgRec = 69.8 on NewsTSC compared to AvgRev = [75.6, 82.2] on established TSC datasets). Reasons include incorrectly resolved relation of target and sentiment-bearing phrases and oﬀ-context dependence. As a major improvement over previous news TSC, we ﬁnd that BERT’s natural language understanding capabilities capture the less explicit sentiment used in news articles.},
	language = {en},
	urldate = {2021-11-26},
	journal = {arXiv:2105.09660 [cs]},
	author = {Hamborg, Felix and Donnay, Karsten and Gipp, Bela},
	year = {2021},
	note = {arXiv: 2105.09660},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
	pages = {156--166},
	file = {Hamborg et al. - 2021 - Towards Target-dependent Sentiment Classification .pdf:files/214/Hamborg et al. - 2021 - Towards Target-dependent Sentiment Classification .pdf:application/pdf},
}

@inproceedings{hamborg_automated_2019-1,
	address = {Champaign, IL, USA},
	title = {Automated {Identification} of {Media} {Bias} by {Word} {Choice} and {Labeling} in {News} {Articles}},
	isbn = {978-1-72811-547-4},
	url = {https://ieeexplore.ieee.org/document/8791197/},
	doi = {10.1109/JCDL.2019.00036},
	urldate = {2021-11-26},
	booktitle = {2019 {ACM}/{IEEE} {Joint} {Conference} on {Digital} {Libraries} ({JCDL})},
	publisher = {IEEE},
	author = {Hamborg, Felix and Zhukova, Anastasia and Gipp, Bela},
	month = jun,
	year = {2019},
	pages = {196--205},
}

@article{ma_characterizing_2018,
	title = {Characterizing {Adversarial} {Subspaces} {Using} {Local} {Intrinsic} {Dimensionality}},
	url = {http://arxiv.org/abs/1801.02613},
	abstract = {Deep Neural Networks (DNNs) have recently been shown to be vulnerable against adversarial examples, which are carefully crafted instances that can mislead DNNs to make errors during prediction. To better understand such attacks, a characterization is needed of the properties of regions (the so-called 'adversarial subspaces') in which adversarial examples lie. We tackle this challenge by characterizing the dimensional properties of adversarial regions, via the use of Local Intrinsic Dimensionality (LID). LID assesses the space-filling capability of the region surrounding a reference example, based on the distance distribution of the example to its neighbors. We first provide explanations about how adversarial perturbation can affect the LID characteristic of adversarial regions, and then show empirically that LID characteristics can facilitate the distinction of adversarial examples generated using state-of-the-art attacks. As a proof-of-concept, we show that a potential application of LID is to distinguish adversarial examples, and the preliminary results show that it can outperform several state-of-the-art detection measures by large margins for five attack strategies considered in this paper across three benchmark datasets. Our analysis of the LID characteristic for adversarial regions not only motivates new directions of effective adversarial defense, but also opens up more challenges for developing new attacks to better understand the vulnerabilities of DNNs.},
	urldate = {2021-11-26},
	journal = {arXiv:1801.02613 [cs]},
	author = {Ma, Xingjun and Li, Bo and Wang, Yisen and Erfani, Sarah M. and Wijewickrema, Sudanthi and Schoenebeck, Grant and Song, Dawn and Houle, Michael E. and Bailey, James},
	month = mar,
	year = {2018},
	note = {arXiv: 1801.02613},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security},
	file = {arXiv Fulltext PDF:files/221/Ma et al. - 2018 - Characterizing Adversarial Subspaces Using Local I.pdf:application/pdf;arXiv.org Snapshot:files/222/1801.html:text/html},
}

@article{pope_intrinsic_2021,
	title = {The {Intrinsic} {Dimension} of {Images} and {Its} {Impact} on {Learning}},
	url = {http://arxiv.org/abs/2104.08894},
	abstract = {It is widely believed that natural image data exhibits low-dimensional structure despite the high dimensionality of conventional pixel representations. This idea underlies a common intuition for the remarkable success of deep learning in computer vision. In this work, we apply dimension estimation tools to popular datasets and investigate the role of low-dimensional structure in deep learning. We find that common natural image datasets indeed have very low intrinsic dimension relative to the high number of pixels in the images. Additionally, we find that low dimensional datasets are easier for neural networks to learn, and models solving these tasks generalize better from training to test data. Along the way, we develop a technique for validating our dimension estimation tools on synthetic data generated by GANs allowing us to actively manipulate the intrinsic dimension by controlling the image generation process. Code for our experiments may be found here https://github.com/ppope/dimensions.},
	urldate = {2021-11-26},
	journal = {arXiv:2104.08894 [cs, stat]},
	author = {Pope, Phillip and Zhu, Chen and Abdelkader, Ahmed and Goldblum, Micah and Goldstein, Tom},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.08894},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, I.2.6, I.5.1, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:files/226/Pope et al. - 2021 - The Intrinsic Dimension of Images and Its Impact o.pdf:application/pdf;arXiv.org Snapshot:files/227/2104.html:text/html},
}

@article{ansuini_intrinsic_2019,
	title = {Intrinsic dimension of data representations in deep neural networks},
	url = {http://arxiv.org/abs/1905.12784},
	abstract = {Deep neural networks progressively transform their inputs across multiple processing layers. What are the geometrical properties of the representations learned by these networks? Here we study the intrinsic dimensionality (ID) of data-representations, i.e. the minimal number of parameters needed to describe a representation. We find that, in a trained network, the ID is orders of magnitude smaller than the number of units in each layer. Across layers, the ID first increases and then progressively decreases in the final layers. Remarkably, the ID of the last hidden layer predicts classification accuracy on the test set. These results can neither be found by linear dimensionality estimates (e.g., with principal component analysis), nor in representations that had been artificially linearized. They are neither found in untrained networks, nor in networks that are trained on randomized labels. This suggests that neural networks that can generalize are those that transform the data into low-dimensional, but not necessarily flat manifolds.},
	urldate = {2021-11-26},
	journal = {arXiv:1905.12784 [cs, stat]},
	author = {Ansuini, Alessio and Laio, Alessandro and Macke, Jakob H. and Zoccolan, Davide},
	month = oct,
	year = {2019},
	note = {arXiv: 1905.12784},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:files/230/Ansuini et al. - 2019 - Intrinsic dimension of data representations in dee.pdf:application/pdf;arXiv.org Snapshot:files/231/1905.html:text/html},
}

@inproceedings{anonymous_understanding_2021,
	title = {Understanding {Graph} {Learning} with {Local} {Intrinsic} {Dimensionality}},
	url = {https://openreview.net/forum?id=DaQVj6qY2-s},
	abstract = {Many real-world problems can be formulated as graphs and solved by graph learning techniques. Whilst the rise of Graph Neural Networks (GNNs) has greatly advanced graph learning, there is still a...},
	language = {en},
	urldate = {2021-11-26},
	author = {Anonymous},
	month = sep,
	year = {2021},
	file = {Snapshot:files/233/forum.html:text/html;Full Text PDF:files/234/Anonymous - 2021 - Understanding Graph Learning with Local Intrinsic .pdf:application/pdf},
}

@article{shahi_exploratory_2020,
	title = {An {Exploratory} {Study} of {COVID}-19 {Misinformation} on {Twitter}},
	url = {http://arxiv.org/abs/2005.05710},
	abstract = {During the COVID-19 pandemic, social media has become a home ground for misinformation. To tackle this infodemic, scientiﬁc oversight, as well as a better understanding by practitioners in crisis management, is needed. We have conducted an exploratory study into the propagation, authors and content of misinformation on Twitter around the topic of COVID-19 in order to gain early insights. We have collected all tweets mentioned in the verdicts of fact-checked claims related to COVID-19 by over 92 professional fact-checking organisations between January and mid-July 2020 and share this corpus with the community. This resulted in 1 500 tweets relating to 1 274 false and 276 partially false claims, respectively. Exploratory analysis of author accounts revealed that the veriﬁed twitter handle(including Organisation/celebrity) are also involved in either creating (new tweets) or spreading (retweet) the misinformation. Additionally, we found that false claims propagate faster than partially false claims. Compare to a background corpus of COVID-19 tweets, tweets with misinformation are more often concerned with discrediting other information on social media. Authors use less tentative language and appear to be more driven by concerns of potential harm to others. Our results enable us to suggest gaps in the current scientiﬁc coverage of the topic as well as propose actions for authorities and social media users to counter misinformation.},
	language = {en},
	urldate = {2021-11-27},
	journal = {arXiv:2005.05710 [cs]},
	author = {Shahi, Gautam Kishore and Dirkson, Anne and Majchrzak, Tim A.},
	month = aug,
	year = {2020},
	note = {arXiv: 2005.05710},
	keywords = {Computer Science - Computers and Society, Computer Science - Social and Information Networks},
	file = {Shahi et al. - 2020 - An Exploratory Study of COVID-19 Misinformation on.pdf:files/235/Shahi et al. - 2020 - An Exploratory Study of COVID-19 Misinformation on.pdf:application/pdf},
}

@article{zarei_first_2020,
	title = {A {First} {Instagram} {Dataset} on {COVID}-19},
	url = {http://arxiv.org/abs/2004.12226},
	abstract = {The novel coronavirus (COVID-19) pandemic outbreak is drastically shaping and reshaping many aspects of our life, with a huge impact on our social life. In this era of lockdown policies in most of the major cities around the world, we see a huge increase in people and professionals’ engagement in social media. Social media is playing an important role in news propagation as well as keeping people in contact. At the same time, this source is both a blessing and a curse as the coronavirus infodemic has become a major concern, and is already a topic that needs special attention and further research. In this paper, we provide a multilingual coronavirus (COVID-19) Instagram dataset that we have been continuously collected since March 30, 2020. We are making our dataset available to the research community at https://github.com/kooshazarei/COVID-19-InstaPostIDs. We believe that this contribution will help the community to better understand the dynamics behind this phenomenon in Instagram, as one of the major social media. This dataset could also help study the propagation of misinformation related to this outbreak.},
	language = {en},
	urldate = {2021-11-29},
	journal = {arXiv:2004.12226 [cs]},
	author = {Zarei, Koosha and Farahbakhsh, Reza and Crespi, Noel and Tyson, Gareth},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.12226},
	keywords = {Computer Science - Social and Information Networks},
	file = {Zarei et al. - 2020 - A First Instagram Dataset on COVID-19.pdf:files/238/Zarei et al. - 2020 - A First Instagram Dataset on COVID-19.pdf:application/pdf},
}

@article{li_exploring_nodate,
	title = {Exploring the {Vulnerability} of {Natural} {Language} {Processing} {Models} via {Universal} {Adversarial} {Texts}},
	abstract = {Universal adversarial texts (UATs) refer to short pieces of text units that can largely affect the predictions of Natural Language Processing (NLP) models. Recent studies on universal adversarial attacks require the availability of validation/test data which may not always be available in practice. In this paper, we propose two types of Data-Free Adjusted Gradient (DFAG) attacks to show that it is possible to generate effective UATs with manually crafted examples. Based on the proposed DFAG attacks, we explore the vulnerability of commonly used NLP models from two perspectives: network architecture and pre-trained embedding. The empirical results on three text classiﬁcation datasets show that: 1) CNNbased and LSTM models are more vulnerable to UATs than self-attention models; 2) the vulnerability/robustness difference between of CNN/LSTM models and self-attention models could be attributed to whether or not they rely on training data artifacts for predictions; and 3) the pre-trained embeddings could expose vulnerability to both UAT and transferred UTA attacks.},
	language = {en},
	author = {Li, Xinzhe and Liu, Ming and Ma, Xingjun and Gao, Longxiang},
	pages = {11},
	file = {Li et al. - Exploring the Vulnerability of Natural Language Pr.pdf:files/239/Li et al. - Exploring the Vulnerability of Natural Language Pr.pdf:application/pdf},
}

@inproceedings{zhou_fake_2019,
	address = {Prague, Czech Republic},
	title = {Fake {News} {Detection} via {NLP} is {Vulnerable} to {Adversarial} {Attacks}:},
	isbn = {978-989-758-350-6},
	shorttitle = {Fake {News} {Detection} via {NLP} is {Vulnerable} to {Adversarial} {Attacks}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0007566307940800},
	doi = {10.5220/0007566307940800},
	language = {en},
	urldate = {2021-11-29},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Agents} and {Artificial} {Intelligence}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Zhou, Zhixuan and Guan, Huankang and Bhat, Meghana and Hsu, Justin},
	year = {2019},
	pages = {794--800},
	file = {Zhou et al. - 2019 - Fake News Detection via NLP is Vulnerable to Adver.pdf:files/240/Zhou et al. - 2019 - Fake News Detection via NLP is Vulnerable to Adver.pdf:application/pdf},
}

@article{wallace_universal_2021,
	title = {Universal {Adversarial} {Triggers} for {Attacking} and {Analyzing} {NLP}},
	url = {http://arxiv.org/abs/1908.07125},
	abstract = {Adversarial examples highlight model vulnerabilities and are useful for evaluation and interpretation. We deﬁne universal adversarial triggers: input-agnostic sequences of tokens that trigger a model to produce a speciﬁc prediction when concatenated to any input from a dataset. We propose a gradientguided search over tokens which ﬁnds short trigger sequences (e.g., one word for classiﬁcation and four words for language modeling) that successfully trigger the target prediction. For example, triggers cause SNLI entailment accuracy to drop from 89.94\% to 0.55\%, 72\% of “why” questions in SQuAD to be answered “to kill american people”, and the GPT-2 language model to spew racist output even when conditioned on non-racial contexts. Furthermore, although the triggers are optimized using white-box access to a speciﬁc model, they transfer to other models for all tasks we consider. Finally, since triggers are input-agnostic, they provide an analysis of global model behavior. For instance, they conﬁrm that SNLI models exploit dataset biases and help to diagnose heuristics learned by reading comprehension models.},
	language = {en},
	urldate = {2021-11-29},
	journal = {arXiv:1908.07125 [cs]},
	author = {Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
	month = jan,
	year = {2021},
	note = {arXiv: 1908.07125},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Wallace et al. - 2021 - Universal Adversarial Triggers for Attacking and A.pdf:files/241/Wallace et al. - 2021 - Universal Adversarial Triggers for Attacking and A.pdf:application/pdf},
}

@article{zhao_what_2021,
	title = {What {Do} {Deep} {Nets} {Learn}? {Class}-wise {Patterns} {Revealed} in the {Input} {Space}},
	shorttitle = {What {Do} {Deep} {Nets} {Learn}?},
	url = {http://arxiv.org/abs/2101.06898},
	abstract = {Deep neural networks (DNNs) are increasingly deployed in different applications to achieve stateof-the-art performance. However, they are often applied as a black box with limited understanding of what knowledge the model has learned from the data. In this paper, we focus on image classiﬁcation and propose a method to visualize and understand the class-wise knowledge (patterns) learned by DNNs under three different settings including natural, backdoor and adversarial. Different to existing visualization methods, our method searches for a single predictive pattern in the pixel space to represent the knowledge learned by the model for each class. Based on the proposed method, we show that DNNs trained on natural (clean) data learn abstract shapes along with some texture, and backdoored models learn a suspicious pattern for the backdoored class. Interestingly, the phenomenon that DNNs can learn a single predictive pattern for each class indicates that DNNs can learn a backdoor even from clean data, and the pattern itself is a backdoor trigger. In the adversarial setting, we show that adversarially trained models tend to learn more simpliﬁed shape patterns. Our method can serve as a useful tool to better understand the knowledge learned by DNNs on different datasets under different settings.},
	language = {en},
	urldate = {2021-11-29},
	journal = {arXiv:2101.06898 [cs]},
	author = {Zhao, Shihao and Ma, Xingjun and Wang, Yisen and Bailey, James and Li, Bo and Jiang, Yu-Gang},
	month = feb,
	year = {2021},
	note = {arXiv: 2101.06898},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhao et al. - 2021 - What Do Deep Nets Learn Class-wise Patterns Revea.pdf:files/242/Zhao et al. - 2021 - What Do Deep Nets Learn Class-wise Patterns Revea.pdf:application/pdf},
}

@incollection{gray_probabilistic_2019,
	edition = {1},
	title = {A probabilistic approach to semantic representation},
	isbn = {978-1-315-78237-9},
	url = {https://www.taylorfrancis.com/books/9781317708322/chapters/10.4324/9781315782379-102},
	abstract = {Semantic networks produced from human data have statistical properties that cannot be easily captured by spatial representations. We explore a probabilistic approach to semantic representation that explicitly models the probability with which words occur in diﬀerent contexts, and hence captures the probabilistic relationships between words. We show that this representation has statistical properties consistent with the large-scale structure of semantic networks constructed by humans, and trace the origins of these properties.},
	language = {en},
	urldate = {2021-11-29},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {Annual} {Conference} of the {Cognitive} {Science} {Society}},
	publisher = {Routledge},
	author = {Griffiths, Thomas L. and Steyvers, Mark},
	editor = {Gray, Wayne D. and Schunn, Christian D.},
	month = apr,
	year = {2019},
	doi = {10.4324/9781315782379-102},
	pages = {381--386},
	file = {Griffiths and Steyvers - 2019 - A probabilistic approach to semantic representatio.pdf:files/251/Griffiths and Steyvers - 2019 - A probabilistic approach to semantic representatio.pdf:application/pdf},
}

@misc{organisation_naming_nodate,
	title = {Naming the coronavirus disease ({COVID}-19) and the virus that causes it},
	url = {https://www.who.int/emergencies/diseases/novel-coronavirus-2019/technical-guidance/naming-the-coronavirus-disease-(covid-2019)-and-the-virus-that-causes-it},
	language = {en},
	urldate = {2021-12-02},
	author = {Organisation, Word Health},
	file = {Snapshot:files/256/naming-the-coronavirus-disease-(covid-2019)-and-the-virus-that-causes-it.html:text/html},
}

@article{bangyal_detection_2021,
	title = {Detection of {Fake} {News} {Text} {Classification} on {COVID}-19 {Using} {Deep} {Learning} {Approaches}},
	volume = {2021},
	issn = {1748-6718, 1748-670X},
	url = {https://www.hindawi.com/journals/cmmm/2021/5514220/},
	doi = {10.1155/2021/5514220},
	abstract = {A vast amount of data is generated every second for microblogs, content sharing via social media sites, and social networking. Twitter is an essential popular microblog where people voice their opinions about daily issues. Recently, analyzing these opinions is the primary concern of Sentiment analysis or opinion mining. Efficiently capturing, gathering, and analyzing sentiments have been challenging for researchers. To deal with these challenges, in this research work, we propose a highly accurate approach for SA of fake news on COVID-19. The fake news dataset contains fake news on COVID-19; we started by data preprocessing (replace the missing value, noise removal, tokenization, and stemming). We applied a semantic model with term frequency and inverse document frequency weighting for data representation. In the measuring and evaluation step, we applied eight machine-learning algorithms such as Naive Bayesian, Adaboost,
              
                
                  K
                
              
              -nearest neighbors, random forest, logistic regression, decision tree, neural networks, and support vector machine and four deep learning CNN, LSTM, RNN, and GRU. Afterward, based on the results, we boiled a highly efficient prediction model with python, and we trained and evaluated the classification model according to the performance measures (confusion matrix, classification rate, true positives rate...), then tested the model on a set of unclassified fake news on COVID-19, to predict the sentiment class of each fake news on COVID-19. Obtained results demonstrate a high accuracy compared to the other models. Finally, a set of recommendations is provided with future directions for this research to help researchers select an efficient sentiment analysis model on Twitter data.},
	language = {en},
	urldate = {2021-12-04},
	journal = {Computational and Mathematical Methods in Medicine},
	author = {Bangyal, Waqas Haider and Qasim, Rukhma and Rehman, Najeeb ur and Ahmad, Zeeshan and Dar, Hafsa and Rukhsar, Laiqa and Aman, Zahra and Ahmad, Jamil},
	editor = {Korobeinikov, Andrei},
	month = nov,
	year = {2021},
	pages = {1--14},
	file = {Bangyal et al. - 2021 - Detection of Fake News Text Classification on COVI.pdf:files/257/Bangyal et al. - 2021 - Detection of Fake News Text Classification on COVI.pdf:application/pdf},
}

@article{chandra_covid-19_2021,
	title = {{COVID}-19 sentiment analysis via deep learning during the rise of novel cases},
	volume = {16},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0255615},
	doi = {10.1371/journal.pone.0255615},
	abstract = {Social scientists and psychologists take interest in understanding how people express emotions and sentiments when dealing with catastrophic events such as natural disasters, political unrest, and terrorism. The COVID-19 pandemic is a catastrophic event that has raised a number of psychological issues such as depression given abrupt social changes and lack of employment. Advancements of deep learning-based language models have been promising for sentiment analysis with data from social networks such as Twitter. Given the situation with COVID-19 pandemic, different countries had different peaks where rise and fall of new cases affected lock-downs which directly affected the economy and employment. During the rise of COVID-19 cases with stricter lock-downs, people have been expressing their sentiments in social media. This can provide a deep understanding of human psychology during catastrophic events. In this paper, we present a framework that employs deep learningbased language models via long short-term memory (LSTM) recurrent neural networks for sentiment analysis during the rise of novel COVID-19 cases in India. The framework features LSTM language model with a global vector embedding and state-of-art BERT language model. We review the sentiments expressed for selective months in 2020 which covers the major peak of novel cases in India. Our framework utilises multi-label sentiment classification where more than one sentiment can be expressed at once. Our results indicate that the majority of the tweets have been positive with high levels of optimism during the rise of the novel COVID-19 cases and the number of tweets significantly lowered towards the peak. We find that the optimistic, annoyed and joking tweets mostly dominate the monthly tweets with much lower portion of negative sentiments. The predictions generally indicate that although the majority have been optimistic, a significant group of population has been annoyed towards the way the pandemic was handled by the authorities.},
	language = {en},
	number = {8},
	urldate = {2021-12-04},
	journal = {PLOS ONE},
	author = {Chandra, Rohitash and Krishna, Aswin},
	editor = {Cotfas, Liviu-Adrian},
	month = aug,
	year = {2021},
	pages = {e0255615},
	file = {Chandra and Krishna - 2021 - COVID-19 sentiment analysis via deep learning duri.pdf:files/259/Chandra and Krishna - 2021 - COVID-19 sentiment analysis via deep learning duri.pdf:application/pdf},
}

@article{ozbay_fake_2020,
	title = {Fake news detection within online social media using supervised artificial intelligence algorithms},
	volume = {540},
	issn = {03784371},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378437119317546},
	doi = {10.1016/j.physa.2019.123174},
	language = {en},
	urldate = {2021-12-04},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Ozbay, Feyza Altunbey and Alatas, Bilal},
	month = feb,
	year = {2020},
	pages = {123174},
}

@article{aggarwal_classification_2018,
	title = {Classification of {Fake} {News} by {Fine}-tuning {Deep} {Bidirectional} {Transformers} based {Language} {Model}},
	issn = {2032-9407},
	url = {http://eudl.eu/doi/10.4108/eai.13-7-2018.163973},
	doi = {10.4108/eai.13-7-2018.163973},
	abstract = {With the ever-increasing rate of information dissemination and absorption, “Fake News” has become a real menace. People these days often fall prey to fake news that is in line with their perception. Checking the authenticity of news articles manually is a time-consuming and laborious task, thus, giving rise to the requirement for automated computational tools that can provide insights about degree of fake ness for news articles. In this paper, a Natural Language Processing (NLP) based mechanism is proposed to combat this challenge of classifying news articles as either fake or real. Transfer learning on the Bidirectional Encoder Representations from Transformers (BERT) language model has been applied for this task. This paper demonstrates how even with minimal text pre-processing, the fine-tuned BERT model is robust enough to perform significantly well on the downstream task of classification of news articles. In addition, LSTM and Gradient Boosted Tree models have been built to perform the task and comparative results are provided for all three models. Fine-tuned BERT model could achieve an accuracy of 97.021\% on NewsFN data and is able to outperform the other two models by approximately eight percent.},
	language = {en},
	urldate = {2021-12-04},
	journal = {ICST Transactions on Scalable Information Systems},
	author = {Aggarwal, Akshay and Chauhan, Aniruddha and Kumar, Deepika and Mittal, Mamta and Verma, Sharad},
	month = jul,
	year = {2018},
	pages = {163973},
	file = {Hamborg et al. - 2019 - Automated identification of media bias in news art.pdf:files/208/Hamborg et al. - 2019 - Automated identification of media bias in news art.pdf:application/pdf;Aggarwal et al. - 2018 - Classification of Fake News by Fine-tuning Deep Bi.pdf:files/265/Aggarwal et al. - 2018 - Classification of Fake News by Fine-tuning Deep Bi.pdf:application/pdf},
}

@article{ullah_survey_2021,
	title = {A {Survey} of {COVID}-19 {Misinformation}: {Datasets}, {Detection} {Techniques} and {Open} {Issues}},
	shorttitle = {A {Survey} of {COVID}-19 {Misinformation}},
	url = {http://arxiv.org/abs/2110.00737},
	abstract = {Misinformation during pandemic situations like COVID-19 is growing rapidly on social media and other platforms. This expeditious growth of misinformation creates adverse effects on the people living in the society. Researchers are trying their best to mitigate this problem using different approaches based on Machine Learning (ML), Deep Learning (DL), and Natural Language Processing (NLP). This survey aims to study different approaches of misinformation detection on COVID-19 in recent literature to help the researchers in this domain. More specifically, we review the different methods used for COVID-19 misinformation detection in their research with an overview of data pre-processing and feature extraction methods to get a better understanding of their work. We also summarize the existing datasets which can be used for further research. Finally, we discuss the limitations of the existing methods and highlight some potential future research directions along this dimension to combat the spreading of misinformation during a pandemic.},
	urldate = {2021-12-05},
	journal = {arXiv:2110.00737 [cs]},
	author = {Ullah, A. R. Sana and Das, Anupam and Das, Anik and Kabir, Muhammad Ashad and Shu, Kai},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.00737},
	keywords = {Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/269/Ullah et al. - 2021 - A Survey of COVID-19 Misinformation Datasets, Det.pdf:application/pdf;arXiv.org Snapshot:files/270/2110.html:text/html},
}

@article{wang_liar_2017,
	title = {"{Liar}, {Liar} {Pants} on {Fire}": {A} {New} {Benchmark} {Dataset} for {Fake} {News} {Detection}},
	shorttitle = {"{Liar}, {Liar} {Pants} on {Fire}"},
	url = {http://arxiv.org/abs/1705.00648},
	abstract = {Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present liar: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from PolitiFact.com, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate meta-data with text. We show that this hybrid approach can improve a text-only deep learning model.},
	urldate = {2021-12-05},
	journal = {arXiv:1705.00648 [cs]},
	author = {Wang, William Yang},
	month = may,
	year = {2017},
	note = {arXiv: 1705.00648},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
	file = {arXiv Fulltext PDF:files/274/Wang - 2017 - Liar, Liar Pants on Fire A New Benchmark Datase.pdf:application/pdf;arXiv.org Snapshot:files/275/1705.html:text/html},
}

@article{bhatt_fake_2022,
	title = {Fake {News} {Detection}: {Experiments} and {Approaches} beyond {Linguistic} {Features}},
	volume = {71},
	shorttitle = {Fake {News} {Detection}},
	url = {http://arxiv.org/abs/2109.12914},
	doi = {10.1007/978-981-16-2937-2_9},
	abstract = {Easier access to the internet and social media has made disseminating information through online sources very easy. Sources like Facebook, Twitter, online news sites and personal blogs of self-proclaimed journalists have become significant players in providing news content. The sheer amount of information and the speed at which it is generated online makes it practically beyond the scope of human verification. There is, hence, a pressing need to develop technologies that can assist humans with automatic fact-checking and reliable identification of fake news. This paper summarizes the multiple approaches that were undertaken and the experiments that were carried out for the task. Credibility information and metadata associated with the news article have been used for improved results. The experiments also show how modelling justification or evidence can lead to improved results. Additionally, the use of visual features in addition to linguistic features is demonstrated. A detailed comparison of the results showing that our models perform significantly well when compared to robust baselines as well as state-of-the-art models are presented.},
	urldate = {2021-12-05},
	journal = {arXiv:2109.12914 [cs]},
	author = {Bhatt, Shaily and Kalra, Sakshi and Goenka, Naman and Sharma, Yashvardhan},
	year = {2022},
	note = {arXiv: 2109.12914},
	keywords = {Computer Science - Computation and Language},
	pages = {113--128},
	file = {arXiv Fulltext PDF:files/277/Bhatt et al. - 2022 - Fake News Detection Experiments and Approaches be.pdf:application/pdf;arXiv.org Snapshot:files/278/2109.html:text/html},
}

@article{stahl_fake_nodate,
	title = {Fake news detection in social media},
	abstract = {Due to the exponential growth of information online, it is becoming impossible to decipher the true from the false. Thus, this leads to the problem of fake news. This research considers previous and current methods for fake news detection in textual formats while detailing how and why fake news exists in the first place. This paper includes a discussion on Linguistic Cue and Network Analysis approaches, and proposes a three-part method using Naïve Bayes Classifier, Support Vector Machines, and Semantic Analysis as an accurate way to detect fake news on social media.},
	language = {en},
	author = {Stahl, Kelly},
	pages = {6},
	file = {Stahl - Fake news detection in social media.pdf:files/279/Stahl - Fake news detection in social media.pdf:application/pdf},
}

@article{yuan_improving_2021,
	title = {Improving fake news detection with domain-adversarial and graph-attention neural network},
	volume = {151},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923621001433},
	doi = {10.1016/j.dss.2021.113633},
	language = {en},
	urldate = {2021-12-05},
	journal = {Decision Support Systems},
	author = {Yuan, Hua and Zheng, Jie and Ye, Qiongwei and Qian, Yu and Zhang, Yan},
	month = dec,
	year = {2021},
	pages = {113633},
}

@article{shim_link2vec-based_2021,
	title = {A link2vec-based fake news detection model using web search results},
	volume = {184},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417421009015},
	doi = {10.1016/j.eswa.2021.115491},
	abstract = {Today, the world is under siege from various kinds of fake news ranging from politics to COVID-19. Thus, many scholars have been researching automatic fake news detection based on artificial intelligence and machine learning (AI/ML) to prevent the spread of fake news. The mainstream research on detecting fake news so far has been text-based detection approaches, but they have inherent limitations such as the difficulty of short text processing and language dependency. Thus, as an alternative to the text-based approach, the context-based approach is emerging. The most common context-based approach the use of distributors’ network information in social media. However, such information is difficult to obtain, and only propagation within a single social media can be traced. Under this background, we propose the use of composition pattern of web links containing news content as a new source of information for fake news detection. To properly vectorize the composition pattern of web links, this study proposes a novel embedding technique, which is called link2vec, an extension of word2vec. To test the effectiveness and language independency of our link2vec-based model, we applied it to two real-world fake news datasets in different languages (English and Korean). As comparison models, we adopted the conventional text-based model and a hybrid model that combined text and whitelist-based link information proposed by a prior study. Results revealed that in the datasets in two languages, the link2vec-based detection models outperformed all the comparison models with statistical significance. Our research is expected to contribute to suggesting a completely new path for effective fake news detection.},
	language = {en},
	urldate = {2021-12-05},
	journal = {Expert Systems with Applications},
	author = {Shim, Jae-Seung and Lee, Yunju and Ahn, Hyunchul},
	month = dec,
	year = {2021},
	keywords = {Deep learning, Fake news detection, Feature selection, Link2vec, Web search result},
	pages = {115491},
	file = {ScienceDirect Snapshot:files/283/S0957417421009015.html:text/html},
}

@article{mehta_transformer-based_2021,
	title = {A transformer-based architecture for fake news classification},
	volume = {11},
	issn = {1869-5450, 1869-5469},
	url = {https://link.springer.com/10.1007/s13278-021-00738-y},
	doi = {10.1007/s13278-021-00738-y},
	language = {en},
	number = {1},
	urldate = {2021-12-05},
	journal = {Social Network Analysis and Mining},
	author = {Mehta, Divyam and Dwivedi, Aniket and Patra, Arunabha and Anand Kumar, M.},
	month = dec,
	year = {2021},
	pages = {39},
}

@article{souza_freire_fake_2021,
	title = {Fake news detection based on explicit and implicit signals of a hybrid crowd: {An} approach inspired in meta-learning},
	volume = {183},
	issn = {09574174},
	shorttitle = {Fake news detection based on explicit and implicit signals of a hybrid crowd},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417421008344},
	doi = {10.1016/j.eswa.2021.115414},
	language = {en},
	urldate = {2021-12-05},
	journal = {Expert Systems with Applications},
	author = {Souza Freire, Paulo Márcio and Matias da Silva, Flávio Roberto and Goldschmidt, Ronaldo Ribeiro},
	month = nov,
	year = {2021},
	pages = {115414},
}

@inproceedings{cabral_fakewhastappbr_2021,
	address = {Online Streaming, --- Select a Country ---},
	title = {{FakeWhastApp}.{BR}: {NLP} and {Machine} {Learning} {Techniques} for {Misinformation} {Detection} in {Brazilian} {Portuguese} {WhatsApp} {Messages}:},
	isbn = {978-989-758-509-8},
	shorttitle = {{FakeWhastApp}.{BR}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010446800630074},
	doi = {10.5220/0010446800630074},
	language = {en},
	urldate = {2021-12-05},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Enterprise} {Information} {Systems}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Cabral, Lucas and Monteiro, José and Franco da Silva, José and Mattos, César and Mourão, Pedro},
	year = {2021},
	pages = {63--74},
	file = {Cabral et al. - 2021 - FakeWhastApp.BR NLP and Machine Learning Techniqu.pdf:files/287/Cabral et al. - 2021 - FakeWhastApp.BR NLP and Machine Learning Techniqu.pdf:application/pdf},
}

@article{lai_human_2019,
	title = {On {Human} {Predictions} with {Explanations} and {Predictions} of {Machine} {Learning} {Models}: {A} {Case} {Study} on {Deception} {Detection}},
	shorttitle = {On {Human} {Predictions} with {Explanations} and {Predictions} of {Machine} {Learning} {Models}},
	url = {http://arxiv.org/abs/1811.07901},
	doi = {10.1145/3287560.3287590},
	abstract = {Humans are the final decision makers in critical tasks that involve ethical and legal concerns, ranging from recidivism prediction, to medical diagnosis, to fighting against fake news. Although machine learning models can sometimes achieve impressive performance in these tasks, these tasks are not amenable to full automation. To realize the potential of machine learning for improving human decisions, it is important to understand how assistance from machine learning models affects human performance and human agency. In this paper, we use deception detection as a testbed and investigate how we can harness explanations and predictions of machine learning models to improve human performance while retaining human agency. We propose a spectrum between full human agency and full automation, and develop varying levels of machine assistance along the spectrum that gradually increase the influence of machine predictions. We find that without showing predicted labels, explanations alone slightly improve human performance in the end task. In comparison, human performance is greatly improved by showing predicted labels ({\textgreater}20\% relative improvement) and can be further improved by explicitly suggesting strong machine performance. Interestingly, when predicted labels are shown, explanations of machine predictions induce a similar level of accuracy as an explicit statement of strong machine performance. Our results demonstrate a tradeoff between human performance and human agency and show that explanations of machine predictions can moderate this tradeoff.},
	urldate = {2021-12-05},
	journal = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
	author = {Lai, Vivian and Tan, Chenhao},
	month = jan,
	year = {2019},
	note = {arXiv: 1811.07901},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Physics - Physics and Society},
	pages = {29--38},
	file = {arXiv Fulltext PDF:files/291/Lai and Tan - 2019 - On Human Predictions with Explanations and Predict.pdf:application/pdf;arXiv.org Snapshot:files/292/1811.html:text/html},
}

@inproceedings{lundberg_unified_2017,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	volume = {30},
	url = {https://proceedings.neurips.cc//paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
	urldate = {2021-12-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lundberg, Scott M and Lee, Su-In},
	year = {2017},
	file = {Full Text PDF:files/294/Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf},
}

@incollection{chakraborty_fighting_2021,
	address = {Cham},
	title = {Fighting an {Infodemic}: {COVID}-19 {Fake} {News} {Dataset}},
	volume = {1402},
	isbn = {978-3-030-73695-8 978-3-030-73696-5},
	shorttitle = {Fighting an {Infodemic}},
	url = {https://link.springer.com/10.1007/978-3-030-73696-5_3},
	language = {en},
	urldate = {2021-12-07},
	booktitle = {Combating {Online} {Hostile} {Posts} in {Regional} {Languages} during {Emergency} {Situation}},
	publisher = {Springer International Publishing},
	author = {Patwa, Parth and Sharma, Shivam and Pykl, Srinivas and Guptha, Vineeth and Kumari, Gitanjali and Akhtar, Md Shad and Ekbal, Asif and Das, Amitava and Chakraborty, Tanmoy},
	editor = {Chakraborty, Tanmoy and Shu, Kai and Bernard, H. Russell and Liu, Huan and Akhtar, Md Shad},
	year = {2021},
	doi = {10.1007/978-3-030-73696-5_3},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {21--29},
	file = {Patwa et al. - 2021 - Fighting an Infodemic COVID-19 Fake News Dataset.pdf:files/295/Patwa et al. - 2021 - Fighting an Infodemic COVID-19 Fake News Dataset.pdf:application/pdf},
}

@article{cui_coaid_2020,
	title = {{CoAID}: {COVID}-19 {Healthcare} {Misinformation} {Dataset}},
	shorttitle = {{CoAID}},
	url = {http://arxiv.org/abs/2006.00885},
	abstract = {As the COVID-19 virus quickly spreads around the world, unfortunately, misinformation related to COVID-19 also gets created and spreads like wild fire. Such misinformation has caused confusion among people, disruptions in society, and even deadly consequences in health problems. To be able to understand, detect, and mitigate such COVID-19 misinformation, therefore, has not only deep intellectual values but also huge societal impacts. To help researchers combat COVID-19 health misinformation, therefore, we present CoAID (Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare misinformation, including fake news on websites and social platforms, along with users' social engagement about such news. CoAID includes 4,251 news, 296,000 related user engagements, 926 social platform posts about COVID-19, and ground truth labels. The dataset is available at: https://github.com/cuilimeng/CoAID.},
	urldate = {2021-12-07},
	journal = {arXiv:2006.00885 [cs]},
	author = {Cui, Limeng and Lee, Dongwon},
	month = nov,
	year = {2020},
	note = {arXiv: 2006.00885},
	keywords = {Computer Science - Computation and Language, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/298/Cui and Lee - 2020 - CoAID COVID-19 Healthcare Misinformation Dataset.pdf:application/pdf;arXiv.org Snapshot:files/299/2006.html:text/html},
}

@article{elhadad_detecting_2020,
	title = {Detecting {Misleading} {Information} on {COVID}-19},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9189767/},
	doi = {10.1109/ACCESS.2020.3022867},
	urldate = {2021-12-07},
	journal = {IEEE Access},
	author = {Elhadad, Mohamed K. and Li, Kin Fun and Gebali, Fayez},
	year = {2020},
	pages = {165201--165215},
	file = {Full Text:files/301/Elhadad et al. - 2020 - Detecting Misleading Information on COVID-19.pdf:application/pdf},
}

@article{hernon_disinformation_1995,
	title = {Disinformation and misinformation through the internet: {Findings} of an exploratory study},
	volume = {12},
	issn = {0740624X},
	shorttitle = {Disinformation and misinformation through the internet},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0740624X95900527},
	doi = {10.1016/0740-624X(95)90052-7},
	language = {en},
	number = {2},
	urldate = {2021-12-08},
	journal = {Government Information Quarterly},
	author = {Hernon, Peter},
	month = jan,
	year = {1995},
	pages = {133--139},
}

@article{patwa_fighting_2021,
	title = {Fighting an {Infodemic}: {COVID}-19 {Fake} {News} {Dataset}},
	volume = {1402},
	shorttitle = {Fighting an {Infodemic}},
	url = {http://arxiv.org/abs/2011.03327},
	doi = {10.1007/978-3-030-73696-5_3},
	abstract = {Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news and rumors are rampant on social media. Believing in rumors can cause significant harm. This is further exacerbated at the time of a pandemic. To tackle this, we curate and release a manually annotated dataset of 10,700 social media posts and articles of real and fake news on COVID-19. We benchmark the annotated dataset with four machine learning baselines - Decision Tree, Logistic Regression, Gradient Boost, and Support Vector Machine (SVM). We obtain the best performance of 93.46\% F1-score with SVM. The data and code is available at: https://github.com/parthpatwa/covid19-fake-news-dectection},
	urldate = {2021-12-08},
	journal = {arXiv:2011.03327 [cs]},
	author = {Patwa, Parth and Sharma, Shivam and Pykl, Srinivas and Guptha, Vineeth and Kumari, Gitanjali and Akhtar, Md Shad and Ekbal, Asif and Das, Amitava and Chakraborty, Tanmoy},
	year = {2021},
	note = {arXiv: 2011.03327},
	keywords = {Computer Science - Computation and Language, Computer Science - Social and Information Networks, Computer Science - Information Retrieval},
	pages = {21--29},
	file = {arXiv Fulltext PDF:files/305/Patwa et al. - 2021 - Fighting an Infodemic COVID-19 Fake News Dataset.pdf:application/pdf;arXiv.org Snapshot:files/306/2011.html:text/html},
}

@misc{noauthor_fake_2021,
	title = {Fake news},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Fake_news&oldid=1058562158},
	abstract = {Fake news is false or misleading information presented as news. It often has the aim of damaging the reputation of a person or entity, or making money through advertising revenue. However, the term does not have a fixed definition, and has been applied more broadly to include any type of false information, including unintentional and unconscious mechanisms, and also by high-profile individuals to apply to any news unfavourable to their personal perspectives.
Once common in print, the prevalence of fake news has increased with the rise of social media, especially the Facebook News Feed. Political polarization, post-truth politics, confirmation bias, and social media algorithms have been implicated in the spread of fake news. It is sometimes generated and propagated by hostile foreign actors, particularly during elections. The use of anonymously-hosted fake news websites has made it difficult to prosecute sources of fake news for libel. In some definitions, fake news includes satirical articles misinterpreted as genuine, and articles that employ sensationalist or clickbait headlines that are not supported in the text.Fake news can reduce the impact of real news by competing with it; a Buzzfeed analysis found that the top fake news stories about the 2016 U.S. presidential election received more engagement on Facebook than top stories from major media outlets. It also has the potential to undermine trust in serious media coverage. The term has at times been used to cast doubt upon legitimate news, and former U.S. president Donald Trump has been credited with popularizing the term by using it to describe any negative press coverage of himself. It has been increasingly criticized, due in part to Trump's misuse, with the British government deciding to avoid the term, as it is "poorly-defined" and "conflates a variety of false information, from genuine error through to foreign interference".Multiple strategies for fighting fake news are currently being actively researched, and need to be tailored to individual types of fake news. Effective self-regulation and legally-enforced regulation of social media and web search engines are needed. The information space needs to be flooded with accurate news to displace fake news. Individuals need to actively confront false narratives when spotted, as well as take care when sharing information via social media. However, reason, the scientific method and critical thinking skills alone are insufficient to counter the broad scope of bad ideas. Overlooked is the power of confirmation bias, motivated reasoning and other cognitive biases that can seriously distort the many facets of immune mental health. Inoculation theory shows promise in designing techniques to make individuals resistant to the lure of fake news, in the same way that a vaccine protects against infectious diseases.},
	language = {en},
	urldate = {2021-12-08},
	journal = {Wikipedia},
	month = dec,
	year = {2021},
	note = {Page Version ID: 1058562158},
	file = {Snapshot:files/309/index.html:text/html},
}

@article{murphy_government_2018,
	title = {Government bans phrase 'fake news'},
	issn = {0307-1235},
	url = {https://www.telegraph.co.uk/technology/2018/10/22/government-bans-phrase-fake-news/},
	abstract = {The government has banned the term \&ldquo;fake news\&rdquo; after urging ministers to use \&ldquo;misinformation\&rdquo; or \&quot;disinformation\&quot; instead.},
	language = {en-GB},
	urldate = {2021-12-08},
	journal = {The Telegraph},
	author = {Murphy, Margi},
	month = oct,
	year = {2018},
	keywords = {Cambridge Analytica, Facebook, Fake news, Standard, Technology},
	file = {Snapshot:files/311/government-bans-phrase-fake-news.html:text/html},
}

@book{molnar_95_nodate,
	title = {9.5 {Shapley} {Values} {\textbar} {Interpretable} {Machine} {Learning}},
	url = {https://christophm.github.io/interpretable-ml-book/shapley.html},
	abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.},
	urldate = {2021-12-08},
	author = {Molnar, Christoph},
	file = {Snapshot:files/313/shapley.html:text/html},
}

@article{li_exploring_2021,
	title = {Exploring {Text}-transformers in {AAAI} 2021 {Shared} {Task}: {COVID}-19 {Fake} {News} {Detection} in {English}},
	shorttitle = {Exploring {Text}-transformers in {AAAI} 2021 {Shared} {Task}},
	url = {http://arxiv.org/abs/2101.02359},
	abstract = {In this paper, we describe our system for the AAAI 2021 shared task of COVID-19 Fake News Detection in English, where we achieved the 3rd position with the weighted F1 score of 0.9859 on the test set. Specifically, we proposed an ensemble method of different pre-trained language models such as BERT, Roberta, Ernie, etc. with various training strategies including warm-up,learning rate schedule and k-fold cross-validation. We also conduct an extensive analysis of the samples that are not correctly classified. The code is available at:https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.},
	urldate = {2021-12-08},
	journal = {arXiv:2101.02359 [cs]},
	author = {Li, Xiangyang and Xia, Yu and Long, Xiang and Li, Zheng and Li, Sujian},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.02359},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:files/316/Li et al. - 2021 - Exploring Text-transformers in AAAI 2021 Shared Ta.pdf:application/pdf;arXiv.org Snapshot:files/317/2101.html:text/html},
}

@article{chen_transformer-based_2021,
	title = {Transformer-based {Language} {Model} {Fine}-tuning {Methods} for {COVID}-19 {Fake} {News} {Detection}},
	url = {http://arxiv.org/abs/2101.05509},
	abstract = {With the pandemic of COVID-19, relevant fake news is spreading all over the sky throughout the social media. Believing in them without discrimination can cause great trouble to people's life. However, universal language models may perform weakly in these fake news detection for lack of large-scale annotated data and sufficient semantic understanding of domain-specific knowledge. While the model trained on corresponding corpora is also mediocre for insufficient learning. In this paper, we propose a novel transformer-based language model fine-tuning approach for these fake news detection. First, the token vocabulary of individual model is expanded for the actual semantics of professional phrases. Second, we adapt the heated-up softmax loss to distinguish the hard-mining samples, which are common for fake news because of the disambiguation of short text. Then, we involve adversarial training to improve the model's robustness. Last, the predicted features extracted by universal language model RoBERTa and domain-specific model CT-BERT are fused by one multiple layer perception to integrate fine-grained and high-level specific representations. Quantitative experimental results evaluated on existing COVID-19 fake news dataset show its superior performances compared to the state-of-the-art methods among various evaluation metrics. Furthermore, the best weighted average F1 score achieves 99.02\%.},
	urldate = {2021-12-08},
	journal = {arXiv:2101.05509 [cs]},
	author = {Chen, Ben and Chen, Bin and Gao, Dehong and Chen, Qijin and Huo, Chengfu and Meng, Xiaonan and Ren, Weijun and Zhou, Yang},
	month = jan,
	year = {2021},
	note = {arXiv: 2101.05509},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:files/320/Chen et al. - 2021 - Transformer-based Language Model Fine-tuning Metho.pdf:application/pdf;arXiv.org Snapshot:files/321/2101.html:text/html},
}

@article{glazkova_g2tmn_2021,
	title = {g2tmn at {Constraint}@{AAAI2021}: {Exploiting} {CT}-{BERT} and {Ensembling} {Learning} for {COVID}-19 {Fake} {News} {Detection}},
	volume = {1402},
	shorttitle = {g2tmn at {Constraint}@{AAAI2021}},
	url = {http://arxiv.org/abs/2012.11967},
	doi = {10.1007/978-3-030-73696-5_12},
	abstract = {The COVID-19 pandemic has had a huge impact on various areas of human life. Hence, the coronavirus pandemic and its consequences are being actively discussed on social media. However, not all social media posts are truthful. Many of them spread fake news that cause panic among readers, misinform people and thus exacerbate the effect of the pandemic. In this paper, we present our results at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in English. In particular, we propose our approach using the transformer-based ensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used, the ways of text preprocessing and adding extra data. As a result, our best model achieved the weighted F1-score of 98.69 on the test set (the first place in the leaderboard) of this shared task that attracted 166 submitted teams in total.},
	urldate = {2021-12-08},
	journal = {arXiv:2012.11967 [cs]},
	author = {Glazkova, Anna and Glazkov, Maksim and Trifonov, Timofey},
	year = {2021},
	note = {arXiv: 2012.11967},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Information Retrieval, 68T50, H.3.3, I.2.7, I.7.m},
	pages = {116--127},
	file = {arXiv Fulltext PDF:files/324/Glazkova et al. - 2021 - g2tmn at Constraint@AAAI2021 Exploiting CT-BERT a.pdf:application/pdf;arXiv.org Snapshot:files/325/2012.html:text/html},
}

@article{gabarron_covid-19-related_2021,
	title = {{COVID}-19-related misinformation on social media: a systematic review},
	volume = {99},
	issn = {0042-9686},
	shorttitle = {{COVID}-19-related misinformation on social media},
	url = {http://www.who.int/entity/bulletin/volumes/99/6/20-276782.pdf},
	doi = {10.2471/BLT.20.276782},
	abstract = {Objective To review misinformation related to coronavirus disease 2019 (COVID-19) on social media during the first phase of the pandemic and to discuss ways of countering misinformation.
Methods We searched PubMed®, Scopus, Embase®, PsycInfo and Google Scholar databases on 5 May 2020 and 1 June 2020 for publications related to COVID-19 and social media which dealt with misinformation and which were primary empirical studies. We followed the preferred reporting items for systematic reviews and meta-analyses and the guidelines for using a measurement tool to assess systematic reviews. Evidence quality and the risk of bias of included studies were classified using the grading of recommendations assessment, development and evaluation approach. The review is registered in the international prospective register of systematic reviews (PROSPERO; CRD42020182154). Findings We identified 22 studies for inclusion in the qualitative synthesis. The proportion of COVID-19 misinformation on social media ranged from 0.2\% (413/212 846) to 28.8\% (194/673) of posts. Of the 22 studies, 11 did not categorize the type of COVID-19-related misinformation, nine described specific misinformation myths and two reported sarcasm or humour related to COVID-19. Only four studies addressed the possible consequences of COVID-19-related misinformation: all reported that it led to fear or panic.
Conclusion Social media play an increasingly important role in spreading both accurate information and misinformation. The findings of this review may help health-care organizations prepare their responses to subsequent phases in the COVID–19 infodemic and to future infodemics in general.},
	language = {en},
	number = {6},
	urldate = {2021-12-08},
	journal = {Bulletin of the World Health Organization},
	author = {Gabarron, Elia and Oyeyemi, Sunday Oluwafemi and Wynn, Rolf},
	month = jun,
	year = {2021},
	pages = {455--463A},
	file = {Gabarron et al. - 2021 - COVID-19-related misinformation on social media a.pdf:files/326/Gabarron et al. - 2021 - COVID-19-related misinformation on social media a.pdf:application/pdf},
}

@article{blei_latent_nodate,
	title = {Latent {Dirichlet} {Allocation}},
	abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a ﬁnite mixture over an underlying set of topics. Each topic is, in turn, modeled as an inﬁnite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efﬁcient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classiﬁcation, and collaborative ﬁltering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
	language = {en},
	author = {Blei, David M},
	pages = {30},
	file = {Blei - Latent Dirichlet Allocation.pdf:files/329/Blei - Latent Dirichlet Allocation.pdf:application/pdf},
}

@article{gao_combining_2017,
	title = {Combining paper cooperative network and topic model for expert topic analysis and extraction},
	volume = {257},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231217301595},
	doi = {https://doi.org/10.1016/j.neucom.2016.12.074},
	abstract = {Paper cooperation network embodies expert topic similarity in an extent, thus, a novel method is proposed for expert topic analysis and extraction by combining paper cooperation network and topic model. In the method, we extract each paper’ author information and construct an expert cooperation network. At the same time, by means of LDA model, a probabilistic topic model is also built to analyze papers’ latent topics. Then, by making full use of the feature that adjacent nodes in the expert cooperation network share similar themes distribution, we makes a constraint on expert topic distribution in Gibbs sampling process of solving the probabilistic topic model. Experimental results on NIPS dataset show that the proposed method can effectively extract expert topics, and the expert paper cooperation network plays a very good supporting role on the extracting task.},
	journal = {Neurocomputing},
	author = {Gao, Shengxiang and Li, Xian and Yu, Zhengtao and Qin, Yu and Zhang, Yang},
	year = {2017},
	keywords = {Expert topic analysis, Expert topic extraction, Gibbs sampling, Paper cooperation network, Probabilistic topic model},
	pages = {136--143},
}

@inproceedings{kim_leveraging_2018,
	address = {Marina Del Rey CA USA},
	title = {Leveraging the {Crowd} to {Detect} and {Reduce} the {Spread} of {Fake} {News} and {Misinformation}},
	isbn = {978-1-4503-5581-0},
	url = {https://dl.acm.org/doi/10.1145/3159652.3159734},
	doi = {10.1145/3159652.3159734},
	language = {en},
	urldate = {2021-12-09},
	booktitle = {Proceedings of the {Eleventh} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Kim, Jooyeon and Tabibian, Behzad and Oh, Alice and Schölkopf, Bernhard and Gomez-Rodriguez, Manuel},
	month = feb,
	year = {2018},
	pages = {324--332},
	file = {Submitted Version:files/334/Kim et al. - 2018 - Leveraging the Crowd to Detect and Reduce the Spre.pdf:application/pdf},
}

@inproceedings{cui_same_2019,
	address = {Vancouver British Columbia Canada},
	title = {{SAME}: sentiment-aware multi-modal embedding for detecting fake news},
	isbn = {978-1-4503-6868-1},
	shorttitle = {{SAME}},
	url = {https://dl.acm.org/doi/10.1145/3341161.3342894},
	doi = {10.1145/3341161.3342894},
	language = {en},
	urldate = {2021-12-09},
	booktitle = {Proceedings of the 2019 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining}},
	publisher = {ACM},
	author = {Cui, Limeng and Wang, Suhang and Lee, Dongwon},
	month = aug,
	year = {2019},
	pages = {41--48},
	file = {Full Text:files/336/Cui et al. - 2019 - SAME sentiment-aware multi-modal embedding for de.pdf:application/pdf},
}

@article{al-rakhami_lies_2020,
	title = {Lies {Kill}, {Facts} {Save}: {Detecting} {COVID}-19 {Misinformation} in {Twitter}},
	volume = {8},
	issn = {2169-3536},
	shorttitle = {Lies {Kill}, {Facts} {Save}},
	doi = {10.1109/ACCESS.2020.3019600},
	abstract = {Online social networks (ONSs) such as Twitter have grown to be very useful tools for the dissemination of information. However, they have also become a fertile ground for the spread of false information, particularly regarding the ongoing coronavirus disease 2019 (COVID-19) pandemic. Best described as an infodemic, there is a great need, now more than ever, for scientific fact-checking and misinformation detection regarding the dangers posed by these tools with regards to COVID-19. In this article, we analyze the credibility of information shared on Twitter pertaining the COVID-19 pandemic. For our analysis, we propose an ensemble-learning-based framework for verifying the credibility of a vast number of tweets. In particular, we carry out analyses of a large dataset of tweets conveying information regarding COVID-19. In our approach, we classify the information into two categories: credible or non-credible. Our classifications of tweet credibility are based on various features, including tweet- and user-level features. We conduct multiple experiments on the collected and labeled dataset. The results obtained with the proposed framework reveal high accuracy in detecting credible and non-credible tweets containing COVID-19 information.},
	journal = {IEEE Access},
	author = {Al-Rakhami, Mabrook S. and Al-Amri, Atif M.},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Classification, COVID-19, Diseases, Feature extraction, machine learning, Machine learning, misinformation, Organizations, Tools, Twitter},
	pages = {155961--155970},
	file = {IEEE Xplore Abstract Record:files/338/9178271.html:text/html;IEEE Xplore Full Text PDF:files/340/Al-Rakhami and Al-Amri - 2020 - Lies Kill, Facts Save Detecting COVID-19 Misinfor.pdf:application/pdf},
}

@article{kar_no_2020,
	title = {No {Rumours} {Please}! {A} {Multi}-{Indic}-{Lingual} {Approach} for {COVID} {Fake}-{Tweet} {Detection}},
	url = {http://arxiv.org/abs/2010.06906},
	abstract = {The sudden widespread menace created by the present global pandemic COVID-19 has had an unprecedented effect on our lives. Man-kind is going through humongous fear and dependence on social media like never before. Fear inevitably leads to panic, speculations, and the spread of misinformation. Many governments have taken measures to curb the spread of such misinformation for public well being. Besides global measures, to have effective outreach, systems for demographically local languages have an important role to play in this effort. Towards this, we propose an approach to detect fake news about COVID-19 early on from social media, such as tweets, for multiple Indic-Languages besides English. In addition, we also create an annotated dataset of Hindi and Bengali tweet for fake news detection. We propose a BERT based model augmented with additional relevant features extracted from Twitter to identify fake tweets. To expand our approach to multiple Indic languages, we resort to mBERT based model which is fine-tuned over created dataset in Hindi and Bengali. We also propose a zero-shot learning approach to alleviate the data scarcity issue for such low resource languages. Through rigorous experiments, we show that our approach reaches around 89\% F-Score in fake tweet detection which supercedes the state-of-the-art (SOTA) results. Moreover, we establish the first benchmark for two Indic-Languages, Hindi and Bengali. Using our annotated data, our model achieves about 79\% F-Score in Hindi and 81\% F-Score for Bengali Tweets. Our zero-shot model achieves about 81\% F-Score in Hindi and 78\% F-Score for Bengali Tweets without any annotated data, which clearly indicates the efficacy of our approach.},
	urldate = {2021-12-09},
	journal = {arXiv:2010.06906 [cs]},
	author = {Kar, Debanjana and Bhardwaj, Mohit and Samanta, Suranjana and Azad, Amar Prakash},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.06906},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/344/Kar et al. - 2020 - No Rumours Please! A Multi-Indic-Lingual Approach .pdf:application/pdf;arXiv.org Snapshot:files/345/2010.html:text/html},
}

@book{barolli_advances_2021,
	address = {Cham},
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {Advances in {Networked}-{Based} {Information} {Systems}: {The} 23rd {International} {Conference} on {Network}-{Based} {Information} {Systems} ({NBiS}-2020)},
	volume = {1264},
	isbn = {978-3-030-57810-7 978-3-030-57811-4},
	shorttitle = {Advances in {Networked}-{Based} {Information} {Systems}},
	url = {https://link.springer.com/10.1007/978-3-030-57811-4},
	language = {en},
	urldate = {2021-12-09},
	publisher = {Springer International Publishing},
	editor = {Barolli, Leonard and Li, Kin Fun and Enokido, Tomoya and Takizawa, Makoto},
	year = {2021},
	doi = {10.1007/978-3-030-57811-4},
}

@misc{noauthor_coronavirus_nodate,
	title = {Coronavirus disease ({COVID}-19) update},
	url = {https://www.who.int/bangladesh/emergencies/coronavirus-disease-(covid-19)-update},
	abstract = {On this website you can find information and guidance from WHO regarding the current outbreak of coronavirus disease (COVID-19) that was first reported from Wuhan, China, on 31 December 2019. Please visit this page for daily updates.},
	language = {en},
	urldate = {2021-12-09},
	file = {Snapshot:files/348/coronavirus-disease-(covid-19)-update.html:text/html},
}

@article{alkhalifa_qmul-sds_2020,
	title = {{QMUL}-{SDS} at {CheckThat}! 2020: {Determining} {COVID}-19 {Tweet} {Check}-{Worthiness} {Using} an {Enhanced} {CT}-{BERT} with {Numeric} {Expressions}},
	shorttitle = {{QMUL}-{SDS} at {CheckThat}! 2020},
	url = {http://arxiv.org/abs/2008.13160},
	abstract = {This paper describes the participation of the QMUL-SDS team for Task 1 of the CLEF 2020 CheckThat! shared task. The purpose of this task is to determine the check-worthiness of tweets about COVID-19 to identify and prioritise tweets that need fact-checking. The overarching aim is to further support ongoing efforts to protect the public from fake news and help people find reliable information. We describe and analyse the results of our submissions. We show that a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions can effectively boost performance from baseline results. We also show results of training data augmentation with rumours on other topics. Our best system ranked fourth in the task with encouraging outcomes showing potential for improved results in the future.},
	urldate = {2021-12-10},
	journal = {arXiv:2008.13160 [cs]},
	author = {Alkhalifa, Rabab and Yoong, Theodore and Kochkina, Elena and Zubiaga, Arkaitz and Liakata, Maria},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.13160},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/354/Alkhalifa et al. - 2020 - QMUL-SDS at CheckThat! 2020 Determining COVID-19 .pdf:application/pdf;arXiv.org Snapshot:files/355/2008.html:text/html},
}

@article{alam_fighting_2020,
	title = {Fighting the {COVID}-19 {Infodemic} in {Social} {Media}: {A} {Holistic} {Perspective} and a {Call} to {Arms}},
	shorttitle = {Fighting the {COVID}-19 {Infodemic} in {Social} {Media}},
	url = {https://arxiv.org/abs/2007.07996v2},
	abstract = {With the outbreak of the COVID-19 pandemic, people turned to social media to read and to share timely information including statistics, warnings, advice, and inspirational stories. Unfortunately, alongside all this useful information, there was also a new blending of medical and political misinformation and disinformation, which gave rise to the first global infodemic. While fighting this infodemic is typically thought of in terms of factuality, the problem is much broader as malicious content includes not only fake news, rumors, and conspiracy theories, but also promotion of fake cures, panic, racism, xenophobia, and mistrust in the authorities, among others. This is a complex problem that needs a holistic approach combining the perspectives of journalists, fact-checkers, policymakers, government entities, social media platforms, and society as a whole. Taking them into account we define an annotation schema and detailed annotation instructions, which reflect these perspectives. We performed initial annotations using this schema, and our initial experiments demonstrated sizable improvements over the baselines. Now, we issue a call to arms to the research community and beyond to join the fight by supporting our crowdsourcing annotation efforts.},
	language = {en},
	urldate = {2021-12-10},
	author = {Alam, Firoj and Dalvi, Fahim and Shaar, Shaden and Durrani, Nadir and Mubarak, Hamdy and Nikolov, Alex and Martino, Giovanni Da San and Abdelali, Ahmed and Sajjad, Hassan and Darwish, Kareem and Nakov, Preslav},
	month = jul,
	year = {2020},
	file = {Snapshot:files/357/2007.html:text/html;Full Text PDF:files/358/Alam et al. - 2020 - Fighting the COVID-19 Infodemic in Social Media A.pdf:application/pdf},
}

@article{zhou_recovery_2020,
	title = {{ReCOVery}: {A} {Multimodal} {Repository} for {COVID}-19 {News} {Credibility} {Research}},
	shorttitle = {{ReCOVery}},
	url = {http://arxiv.org/abs/2006.05557},
	doi = {10.1145/3340531.3412880},
	abstract = {First identified in Wuhan, China, in December 2019, the outbreak of COVID-19 has been declared as a global emergency in January, and a pandemic in March 2020 by the World Health Organization (WHO). Along with this pandemic, we are also experiencing an "infodemic" of information with low credibility such as fake news and conspiracies. In this work, we present ReCOVery, a repository designed and constructed to facilitate research on combating such information regarding COVID-19. We first broadly search and investigate {\textasciitilde}2,000 news publishers, from which 60 are identified with extreme [high or low] levels of credibility. By inheriting the credibility of the media on which they were published, a total of 2,029 news articles on coronavirus, published from January to May 2020, are collected in the repository, along with 140,820 tweets that reveal how these news articles have spread on the Twitter social network. The repository provides multimodal information of news articles on coronavirus, including textual, visual, temporal, and network information. The way that news credibility is obtained allows a trade-off between dataset scalability and label accuracy. Extensive experiments are conducted to present data statistics and distributions, as well as to provide baseline performances for predicting news credibility so that future methods can be compared. Our repository is available at http://coronavirus-fakenews.com.},
	urldate = {2021-12-10},
	journal = {Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
	author = {Zhou, Xinyi and Mulay, Apurva and Ferrara, Emilio and Zafarani, Reza},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.05557},
	keywords = {Computer Science - Social and Information Networks, Computer Science - Information Retrieval},
	pages = {3205--3212},
	file = {arXiv Fulltext PDF:files/367/Zhou et al. - 2020 - ReCOVery A Multimodal Repository for COVID-19 New.pdf:application/pdf;arXiv.org Snapshot:files/368/2006.html:text/html},
}

@article{cui_coaid_2020-1,
	title = {{CoAID}: {COVID}-19 {Healthcare} {Misinformation} {Dataset}},
	shorttitle = {{CoAID}},
	url = {http://arxiv.org/abs/2006.00885},
	abstract = {As the COVID-19 virus quickly spreads around the world, unfortunately, misinformation related to COVID-19 also gets created and spreads like wild fire. Such misinformation has caused confusion among people, disruptions in society, and even deadly consequences in health problems. To be able to understand, detect, and mitigate such COVID-19 misinformation, therefore, has not only deep intellectual values but also huge societal impacts. To help researchers combat COVID-19 health misinformation, therefore, we present CoAID (Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare misinformation, including fake news on websites and social platforms, along with users' social engagement about such news. CoAID includes 4,251 news, 296,000 related user engagements, 926 social platform posts about COVID-19, and ground truth labels. The dataset is available at: https://github.com/cuilimeng/CoAID.},
	urldate = {2021-12-10},
	journal = {arXiv:2006.00885 [cs]},
	author = {Cui, Limeng and Lee, Dongwon},
	month = nov,
	year = {2020},
	note = {arXiv: 2006.00885},
	keywords = {Computer Science - Computation and Language, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/369/Cui and Lee - 2020 - CoAID COVID-19 Healthcare Misinformation Dataset.pdf:application/pdf;arXiv.org Snapshot:files/370/2006.html:text/html},
}

@article{abdul-mageed_mega-cov_2021,
	title = {Mega-{COV}: {A} {Billion}-{Scale} {Dataset} of 100+ {Languages} for {COVID}-19},
	shorttitle = {Mega-{COV}},
	url = {http://arxiv.org/abs/2005.06012},
	abstract = {We describe Mega-COV, a billion-scale dataset from Twitter for studying COVID-19. The dataset is diverse (covers 268 countries), longitudinal (goes as back as 2007), multilingual (comes in 100+ languages), and has a significant number of location-tagged tweets ({\textasciitilde}169M tweets). We release tweet IDs from the dataset. We also develop and release two powerful models, one for identifying whether or not a tweet is related to the pandemic (best F1=97\%) and another for detecting misinformation about COVID-19 (best F1=92\%). A human annotation study reveals the utility of our models on a subset of Mega-COV. Our data and models can be useful for studying a wide host of phenomena related to the pandemic. Mega-COV and our models are publicly available.},
	urldate = {2021-12-10},
	journal = {arXiv:2005.06012 [cs]},
	author = {Abdul-Mageed, Muhammad and Elmadany, AbdelRahim and Nagoudi, El Moatez Billah and Pabbi, Dinesh and Verma, Kunal and Lin, Rannie},
	month = feb,
	year = {2021},
	note = {arXiv: 2005.06012},
	keywords = {Computer Science - Computation and Language, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/372/Abdul-Mageed et al. - 2021 - Mega-COV A Billion-Scale Dataset of 100+ Language.pdf:application/pdf;arXiv.org Snapshot:files/373/2005.html:text/html},
}

@article{cheng_covid-19_2021,
	title = {A {COVID}-19 {Rumor} {Dataset}},
	volume = {12},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2021.644801},
	doi = {10.3389/fpsyg.2021.644801},
	urldate = {2021-12-10},
	journal = {Frontiers in Psychology},
	author = {Cheng, Mingxi and Wang, Songli and Yan, Xiaofeng and Yang, Tianqi and Wang, Wenshuo and Huang, Zehao and Xiao, Xiongye and Nazarian, Shahin and Bogdan, Paul},
	year = {2021},
	pages = {1566},
	file = {Full Text PDF:files/382/Cheng et al. - 2021 - A COVID-19 Rumor Dataset.pdf:application/pdf},
}

@misc{noauthor_types_nodate,
	title = {Types, sources, and claims of {COVID}-19 misinformation {\textbar} {Reuters} {Institute} for the {Study} of {Journalism}},
	url = {https://reutersinstitute.politics.ox.ac.uk/types-sources-and-claims-covid-19-misinformation},
	urldate = {2021-12-10},
	file = {Types, sources, and claims of COVID-19 misinformation | Reuters Institute for the Study of Journalism:files/386/types-sources-and-claims-covid-19-misinformation.html:text/html},
}

@article{shahi_fakecovid_2020,
	title = {{FakeCovid} -- {A} {Multilingual} {Cross}-domain {Fact} {Check} {News} {Dataset} for {COVID}-19},
	url = {http://arxiv.org/abs/2006.11343},
	doi = {10.36190/2020.14},
	abstract = {In this paper, we present a first multilingual cross-domain dataset of 5182 fact-checked news articles for COVID-19, collected from 04/01/2020 to 15/05/2020. We have collected the fact-checked articles from 92 different fact-checking websites after obtaining references from Poynter and Snopes. We have manually annotated articles into 11 different categories of the fact-checked news according to their content. The dataset is in 40 languages from 105 countries. We have built a classifier to detect fake news and present results for the automatic fake news detection and its class. Our model achieves an F1 score of 0.76 to detect the false class and other fact check articles. The FakeCovid dataset is available at Github.},
	urldate = {2021-12-10},
	journal = {arXiv:2006.11343 [cs]},
	author = {Shahi, Gautam Kishore and Nandini, Durgesh},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.11343},
	keywords = {Computer Science - Computers and Society, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/389/Shahi and Nandini - 2020 - FakeCovid -- A Multilingual Cross-domain Fact Chec.pdf:application/pdf;arXiv.org Snapshot:files/390/2006.html:text/html},
}

@article{cheng_deciphering_2021,
	title = {Deciphering the laws of social network-transcendent {COVID}-19 misinformation dynamics and implications for combating misinformation phenomena},
	volume = {11},
	copyright = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-89202-7},
	doi = {10.1038/s41598-021-89202-7},
	abstract = {The global rise of COVID-19 health risk has triggered the related misinformation infodemic. We present the first analysis of COVID-19 misinformation networks and determine few of its implications. Firstly, we analyze the spread trends of COVID-19 misinformation and discover that the COVID-19 misinformation statistics are well fitted by a log-normal distribution. Secondly, we form misinformation networks by taking individual misinformation as a node and similarity between misinformation nodes as links, and we decipher the laws of COVID-19 misinformation network evolution: (1) We discover that misinformation evolves to optimize the network information transfer over time with the sacrifice of robustness. (2) We demonstrate the co-existence of fit get richer and rich get richer phenomena in misinformation networks. (3) We show that a misinformation network evolution with node deletion mechanism captures well the public attention shift on social media. Lastly, we present a network science inspired deep learning framework to accurately predict which Twitter posts are likely to become central nodes (i.e., high centrality) in a misinformation network from only one sentence without the need to know the whole network topology. With the network analysis and the central node prediction, we propose that if we correctly suppress certain central nodes in the misinformation network, the information transfer of network would be severely impacted.},
	language = {en},
	number = {1},
	urldate = {2021-12-10},
	journal = {Scientific Reports},
	author = {Cheng, Mingxi and Yin, Chenzhong and Nazarian, Shahin and Bogdan, Paul},
	month = may,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Applied mathematics;Complex networks
Subject\_term\_id: applied-mathematics;complex-networks},
	keywords = {Applied mathematics, Complex networks},
	pages = {10424},
	file = {Full Text PDF:files/392/Cheng et al. - 2021 - Deciphering the laws of social network-transcenden.pdf:application/pdf},
}

@article{chen_tracking_2020,
	title = {Tracking {Social} {Media} {Discourse} {About} the {COVID}-19 {Pandemic}: {Development} of a {Public} {Coronavirus} {Twitter} {Data} {Set}},
	volume = {6},
	issn = {2369-2960},
	shorttitle = {Tracking {Social} {Media} {Discourse} {About} the {COVID}-19 {Pandemic}},
	url = {http://arxiv.org/abs/2003.07372},
	doi = {10.2196/19273},
	abstract = {At the time of this writing, the novel coronavirus (COVID-19) pandemic outbreak has already put tremendous strain on many countries' citizens, resources and economies around the world. Social distancing measures, travel bans, self-quarantines, and business closures are changing the very fabric of societies worldwide. With people forced out of public spaces, much conversation about these phenomena now occurs online, e.g., on social media platforms like Twitter. In this paper, we describe a multilingual coronavirus (COVID-19) Twitter dataset that we have been continuously collecting since January 22, 2020. We are making our dataset available to the research community (https://github.com/echen102/COVID-19-TweetIDs). It is our hope that our contribution will enable the study of online conversation dynamics in the context of a planetary-scale epidemic outbreak of unprecedented proportions and implications. This dataset could also help track scientific coronavirus misinformation and unverified rumors, or enable the understanding of fear and panic -- and undoubtedly more. Ultimately, this dataset may contribute towards enabling informed solutions and prescribing targeted policy interventions to fight this global crisis.},
	number = {2},
	urldate = {2021-12-11},
	journal = {JMIR Public Health and Surveillance},
	author = {Chen, Emily and Lerman, Kristina and Ferrara, Emilio},
	month = may,
	year = {2020},
	note = {arXiv: 2003.07372},
	keywords = {Computer Science - Social and Information Networks, Quantitative Biology - Populations and Evolution},
	pages = {e19273},
	file = {arXiv Fulltext PDF:files/394/Chen et al. - 2020 - Tracking Social Media Discourse About the COVID-19.pdf:application/pdf;arXiv.org Snapshot:files/395/2003.html:text/html},
}

@article{sharma_covid-19_2020,
	title = {{COVID}-19 on {Social} {Media}: {Analyzing} {Misinformation} in {Twitter} {Conversations}},
	shorttitle = {{COVID}-19 on {Social} {Media}},
	url = {http://arxiv.org/abs/2003.12309},
	abstract = {The ongoing Coronavirus (COVID-19) pandemic highlights the inter-connectedness of our present-day globalized world. With social distancing policies in place, virtual communication has become an important source of (mis)information. As increasing number of people rely on social media platforms for news, identifying misinformation and uncovering the nature of online discourse around COVID-19 has emerged as a critical task. To this end, we collected streaming data related to COVID-19 using the Twitter API, starting March 1, 2020. We identified unreliable and misleading contents based on fact-checking sources, and examined the narratives promoted in misinformation tweets, along with the distribution of engagements with these tweets. In addition, we provide examples of the spreading patterns of prominent misinformation tweets. The analysis is presented and updated on a publically accessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to track the nature of online discourse and misinformation about COVID-19 on Twitter from March 1 - June 5, 2020. The dashboard provides a daily list of identified misinformation tweets, along with topics, sentiments, and emerging trends in the COVID-19 Twitter discourse. The dashboard is provided to improve visibility into the nature and quality of information shared online, and provide real-time access to insights and information extracted from the dataset.},
	urldate = {2021-12-11},
	journal = {arXiv:2003.12309 [cs]},
	author = {Sharma, Karishma and Seo, Sungyong and Meng, Chuizheng and Rambhatla, Sirisha and Liu, Yan},
	month = oct,
	year = {2020},
	note = {arXiv: 2003.12309},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/397/Sharma et al. - 2020 - COVID-19 on Social Media Analyzing Misinformation.pdf:application/pdf;arXiv.org Snapshot:files/398/2003.html:text/html},
}

@article{yang_municipal_2021,
	title = {Municipal {Solid} {Waste} {Forecasting} in {China} {Based} on {Machine} {Learning} {Models}},
	volume = {9},
	issn = {2296-598X},
	url = {https://www.frontiersin.org/articles/10.3389/fenrg.2021.763977/full},
	doi = {10.3389/fenrg.2021.763977},
	abstract = {As the largest producing country of municipal solid waste (MSW) around the world, China is always challenged by a lower utilization rate of MSW due to a lack of a smart MSW forecasting strategy. This paper mainly aims to construct an effective MSW prediction model to handle this problem by using machine learning techniques. Based on the empirical analysis of provincial panel data from 2008 to 2019 in China, we ﬁnd that the Deep Neural Network (DNN) model performs best among all machine learning models. Additionally, we introduce the SHapley Additive exPlanation (SHAP) method to unravel the correlation between MSW production and socioeconomic features (e.g., total regional GDP, population density). We also ﬁnd the increase of urban population and agglomeration of wholesales and retails industries can positively promote the production of MSW in regions of high economic development, and vice versa. These results can be of help in the planning, design, and implementation of solid waste management system in China.},
	language = {en},
	urldate = {2021-12-12},
	journal = {Frontiers in Energy Research},
	author = {Yang, Liping and Zhao, Yigang and Niu, Xiaxia and Song, Zisheng and Gao, Qingxian and Wu, Jun},
	month = nov,
	year = {2021},
	pages = {763977},
	file = {Yang et al. - 2021 - Municipal Solid Waste Forecasting in China Based o.pdf:files/399/Yang et al. - 2021 - Municipal Solid Waste Forecasting in China Based o.pdf:application/pdf},
}

@article{sanchez-garces_exploratory_2021,
	title = {Exploratory {Analysis} of {Fundamental} {Spiritual} {Support} {Factors} to a {Positive} {Attitude} in {Patients} with {COVID}-19 {Using} {Natural}-{Language} {Processing} {Algorithms}},
	volume = {11},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/11/20/9524},
	doi = {10.3390/app11209524},
	abstract = {The SARS-CoV-2 virus that causes COVID-19 affects the respiratory tract and is highly infectious. Those patients who knew that the disease could cause death or that their healing process is quite painful because of the symptoms and conditions developed extreme stress, anxiety, and depression, which aggravated the effects of the disease. Therefore, it is vital to conduct research to analyze these effects and generate self-help and support mechanisms during the disease process. This paper presents exploratory analysis related to stress, coping attitudes, emotional responses, and sources of support that were vital in patients affected by COVID-19; the focus of this study is the consideration of the spiritual factor, which may influence religious resilience that allows for a positive attitude and tenacity. To carry out this research, interviews were conducted with patients who had suffered from COVID-19 disease, and the collected information was processed using textmining techniques using a two-phase methodology. The first phase is based on the Colaizzi method. Interview responses were coded through the search for patterns in the key phrases, and these codes were grouped, forming semantic relationships. In the second phase, natural-language processing algorithms (WordCloud, WordEmbedding, sentiment analysis of opinions) were used, summarizing the interviews in relevant factors of the patient’s experience during the disease. Spiritual resilience stood out the most of all key phrases of the code group tables. Likewise, words such as security, confidence, tranquility, and peace indicated that the patients took a positive attitude towards the symptoms and complications of the disease. Therefore, it is important to be the resilience to face a crisis process, and one of the factors that generated such resilience in COVID-19 patients was religious faith, which was expressed in the interviews using the factors of security, trust, promises of healing, tranquility, and the impossibility of discouragement. All this contributed to the positive attitude of the interviewees during the process of recovery from the disease.},
	language = {en},
	number = {20},
	urldate = {2021-12-12},
	journal = {Applied Sciences},
	author = {Sánchez-Garcés, Jorge and López-Gonzales, Javier Linkolk and Palacio-Farfán, Miguel and Coronel-Sacón, Víctor and Ferney-Teheran, Yonny and Peñuela-Pineda, Jahisber and Avila-George, Himer},
	month = oct,
	year = {2021},
	pages = {9524},
	file = {Sánchez-Garcés et al. - 2021 - Exploratory Analysis of Fundamental Spiritual Supp.pdf:files/401/Sánchez-Garcés et al. - 2021 - Exploratory Analysis of Fundamental Spiritual Supp.pdf:application/pdf},
}

@article{lundberg_local_2020,
	title = {From local explanations to global understanding with explainable {AI} for trees},
	volume = {2},
	issn = {2522-5839},
	url = {http://www.nature.com/articles/s42256-019-0138-9},
	doi = {10.1038/s42256-019-0138-9},
	language = {en},
	number = {1},
	urldate = {2021-12-12},
	journal = {Nature Machine Intelligence},
	author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
	month = jan,
	year = {2020},
	pages = {56--67},
	file = {Accepted Version:files/404/Lundberg et al. - 2020 - From local explanations to global understanding wi.pdf:application/pdf},
}

@inproceedings{lundberg_unified_2017-1,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	volume = {30},
	url = {https://proceedings.neurips.cc//paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
	urldate = {2021-12-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lundberg, Scott M and Lee, Su-In},
	year = {2017},
	file = {Full Text PDF:files/406/Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf},
}

@article{ayoub_combat_2021,
	title = {Combat {COVID}-19 {Infodemic} {Using} {Explainable} {Natural} {Language} {Processing} {Models}},
	url = {http://arxiv.org/abs/2103.00747},
	abstract = {Misinformation of COVID-19 is prevalent on social media as the pandemic unfolds, and the associated risks are extremely high. Thus, it is critical to detect and combat such misinformation. Recently, deep learning models using natural language processing techniques, such as BERT (Bidirectional Encoder Representations from Transformers), have achieved great successes in detecting misinformation. In this paper, we proposed an explainable natural language processing model based on DistilBERT and SHAP (Shapley Additive exPlanations) to combat misinformation about COVID-19 due to their efficiency and effectiveness. First, we collected a dataset of 984 claims about COVID-19 with fact checking. By augmenting the data using back-translation, we doubled the sample size of the dataset and the DistilBERT model was able to obtain good performance (accuracy: 0.972; areas under the curve: 0.993) in detecting misinformation about COVID-19. Our model was also tested on a larger dataset for AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good performance (accuracy: 0.938; areas under the curve: 0.985). The performance on both datasets was better than traditional machine learning models. Second, in order to boost public trust in model prediction, we employed SHAP to improve model explainability, which was further evaluated using a between-subjects experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE), and text+SHAP explanation+source and evidence (TSESE). The participants were significantly more likely to trust and share information related to COVID-19 in the TSE and TSESE conditions than in the T condition. Our results provided good implications in detecting misinformation about COVID-19 and improving public trust.},
	urldate = {2021-12-12},
	journal = {arXiv:2103.00747 [cs]},
	author = {Ayoub, Jackie and Yang, X. Jessie and Zhou, Feng},
	month = feb,
	year = {2021},
	note = {arXiv: 2103.00747},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:files/408/Ayoub et al. - 2021 - Combat COVID-19 Infodemic Using Explainable Natura.pdf:application/pdf;arXiv.org Snapshot:files/410/2103.html:text/html},
}

@inproceedings{lai_human_2019-1,
	address = {New York, NY, USA},
	series = {{FAT}* '19},
	title = {On {Human} {Predictions} with {Explanations} and {Predictions} of {Machine} {Learning} {Models}: {A} {Case} {Study} on {Deception} {Detection}},
	isbn = {978-1-4503-6125-5},
	shorttitle = {On {Human} {Predictions} with {Explanations} and {Predictions} of {Machine} {Learning} {Models}},
	url = {https://doi.org/10.1145/3287560.3287590},
	doi = {10.1145/3287560.3287590},
	abstract = {Humans are the final decision makers in critical tasks that involve ethical and legal concerns, ranging from recidivism prediction, to medical diagnosis, to fighting against fake news. Although machine learning models can sometimes achieve impressive performance in these tasks, these tasks are not amenable to full automation. To realize the potential of machine learning for improving human decisions, it is important to understand how assistance from machine learning models affects human performance and human agency. In this paper, we use deception detection as a testbed and investigate how we can harness explanations and predictions of machine learning models to improve human performance while retaining human agency. We propose a spectrum between full human agency and full automation, and develop varying levels of machine assistance along the spectrum that gradually increase the influence of machine predictions. We find that without showing predicted labels, explanations alone slightly improve human performance in the end task. In comparison, human performance is greatly improved by showing predicted labels ({\textgreater}20\% relative improvement) and can be further improved by explicitly suggesting strong machine performance. Interestingly, when predicted labels are shown, explanations of machine predictions induce a similar level of accuracy as an explicit statement of strong machine performance. Our results demonstrate a tradeoff between human performance and human agency and show that explanations of machine predictions can moderate this tradeoff.},
	urldate = {2021-12-12},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Lai, Vivian and Tan, Chenhao},
	month = jan,
	year = {2019},
	keywords = {explanations, human agency, human performance, predictions},
	pages = {29--38},
	file = {Submitted Version:files/414/Lai and Tan - 2019 - On Human Predictions with Explanations and Predict.pdf:application/pdf},
}

@inproceedings{perrio_cxp949_2020,
	address = {Online},
	title = {{CXP949} at {WNUT}-2020 {Task} 2: {Extracting} {Informative} {COVID}-19 {Tweets} - {RoBERTa} {Ensembles} and {The} {Continued} {Relevance} of {Handcrafted} {Features}},
	shorttitle = {{CXP949} at {WNUT}-2020 {Task} 2},
	url = {https://aclanthology.org/2020.wnut-1.48},
	doi = {10.18653/v1/2020.wnut-1.48},
	abstract = {This paper presents our submission to Task 2 of the Workshop on Noisy User-generated Text. We explore improving the performance of a pre-trained transformer-based language model fine-tuned for text classification through an ensemble implementation that makes use of corpus level information and a handcrafted feature. We test the effectiveness of including the aforementioned features in accommodating the challenges of a noisy data set centred on a specific subject outside the remit of the pre-training data. We show that inclusion of additional features can improve classification results and achieve a score within 2 points of the top performing team.},
	urldate = {2021-12-12},
	booktitle = {Proceedings of the {Sixth} {Workshop} on {Noisy} {User}-generated {Text} ({W}-{NUT} 2020)},
	publisher = {Association for Computational Linguistics},
	author = {Perrio, Calum and Tayyar Madabushi, Harish},
	month = nov,
	year = {2020},
	pages = {352--358},
	file = {Full Text PDF:files/416/Perrio and Tayyar Madabushi - 2020 - CXP949 at WNUT-2020 Task 2 Extracting Informative.pdf:application/pdf},
}

@inproceedings{zhou_recovery_2020-1,
	address = {Virtual Event Ireland},
	title = {{ReCOVery}: {A} {Multimodal} {Repository} for {COVID}-19 {News} {Credibility} {Research}},
	isbn = {978-1-4503-6859-9},
	shorttitle = {{ReCOVery}},
	url = {https://dl.acm.org/doi/10.1145/3340531.3412880},
	doi = {10.1145/3340531.3412880},
	abstract = {First identified in Wuhan, China, in December 2019, the outbreak of COVID-19 has been declared as a global emergency in January, and a pandemic in March 2020 by the World Health Organization (WHO). Along with this pandemic, we are also experiencing an “infodemic” of information with low credibility such as fake news and conspiracies. In this work, we present ReCOVery, a repository designed and constructed to facilitate research on combating such information regarding COVID-19. We first broadly search and investigate ∼2,000 news publishers, from which 60 are identified with extreme [high or low] levels of credibility. By inheriting the credibility of the media on which they were published, a total of 2,029 news articles on coronavirus, published from January to May 2020, are collected in the repository, along with 140,820 tweets that reveal how these news articles have spread on the Twitter social network. The repository provides multimodal information of news articles on coronavirus, including textual, visual, temporal, and network information. The way that news credibility is obtained allows a trade-off between dataset scalability and label accuracy. Extensive experiments are conducted to present data statistics and distributions, as well as to provide baseline performances for predicting news credibility so that future methods can be compared. Our repository is available at http://coronavirus-fakenews.com.},
	language = {en},
	urldate = {2021-12-12},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	publisher = {ACM},
	author = {Zhou, Xinyi and Mulay, Apurva and Ferrara, Emilio and Zafarani, Reza},
	month = oct,
	year = {2020},
	pages = {3205--3212},
	file = {Zhou et al. - 2020 - ReCOVery A Multimodal Repository for COVID-19 New.pdf:files/417/Zhou et al. - 2020 - ReCOVery A Multimodal Repository for COVID-19 New.pdf:application/pdf},
}

@article{memon_characterizing_2020,
	title = {Characterizing {COVID}-19 {Misinformation} {Communities} {Using} a {Novel} {Twitter} {Dataset}},
	url = {http://arxiv.org/abs/2008.00791},
	abstract = {From conspiracy theories to fake cures and fake treatments, COVID-19 has become a hot-bed for the spread of misinformation online. It is more important than ever to identify methods to debunk and correct false information online. In this paper, we present a methodology and analyses to characterize the two competing COVID-19 misinformation communities online: (i) misinformed users or users who are actively posting misinformation, and (ii) informed users or users who are actively spreading true information, or calling out misinformation. The goals of this study are two-fold: (i) collecting a diverse set of annotated COVID-19 Twitter dataset that can be used by the research community to conduct meaningful analysis; and (ii) characterizing the two target communities in terms of their network structure, linguistic patterns, and their membership in other communities. Our analyses show that COVID-19 misinformed communities are denser, and more organized than informed communities, with a possibility of a high volume of the misinformation being part of disinformation campaigns. Our analyses also suggest that a large majority of misinformed users may be anti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19 informed users tend to use more narratives than misinformed users.},
	urldate = {2021-12-12},
	journal = {arXiv:2008.00791 [cs]},
	author = {Memon, Shahan Ali and Carley, Kathleen M.},
	month = sep,
	year = {2020},
	note = {arXiv: 2008.00791},
	keywords = {Computer Science - Computation and Language, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/421/Memon and Carley - 2020 - Characterizing COVID-19 Misinformation Communities.pdf:application/pdf;arXiv.org Snapshot:files/422/2008.html:text/html},
}

@inproceedings{kim_examples_2016,
	title = {Examples are not enough, learn to criticize! {Criticism} for {Interpretability}},
	volume = {29},
	url = {https://papers.nips.cc/paper/2016/hash/5680522b8e2bb01943234bce7bf84534-Abstract.html},
	urldate = {2021-12-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Kim, Been and Khanna, Rajiv and Koyejo, Oluwasanmi O},
	year = {2016},
	file = {Full Text PDF:files/429/Kim et al. - 2016 - Examples are not enough, learn to criticize! Criti.pdf:application/pdf},
}

@inproceedings{ribeiro_why_2016,
	address = {San Francisco California USA},
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939778},
	doi = {10.1145/2939672.2939778},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classiﬁer in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the ﬂexibility of these methods by explaining diﬀerent models for text (e.g. random forests) and image classiﬁcation (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classiﬁer, and identifying why a classiﬁer should not be trusted.},
	language = {en},
	urldate = {2021-12-19},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = aug,
	year = {2016},
	pages = {1135--1144},
	file = {Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:files/430/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf},
}

@article{yang_checked_2021,
	title = {{CHECKED}: {Chinese} {COVID}-19 fake news dataset},
	volume = {11},
	issn = {1869-5450, 1869-5469},
	shorttitle = {{CHECKED}},
	url = {https://link.springer.com/10.1007/s13278-021-00766-8},
	doi = {10.1007/s13278-021-00766-8},
	language = {en},
	number = {1},
	urldate = {2021-12-19},
	journal = {Social Network Analysis and Mining},
	author = {Yang, Chen and Zhou, Xinyi and Zafarani, Reza},
	month = dec,
	year = {2021},
	pages = {58},
	file = {Full Text:files/433/Yang et al. - 2021 - CHECKED Chinese COVID-19 fake news dataset.pdf:application/pdf},
}

@article{glazkova_g2tmn_2021-1,
	title = {g2tmn at {Constraint}@{AAAI2021}: {Exploiting} {CT}-{BERT} and {Ensembling} {Learning} for {COVID}-19 {Fake} {News} {Detection}},
	volume = {1402},
	shorttitle = {g2tmn at {Constraint}@{AAAI2021}},
	url = {http://arxiv.org/abs/2012.11967},
	doi = {10.1007/978-3-030-73696-5_12},
	abstract = {The COVID-19 pandemic has had a huge impact on various areas of human life. Hence, the coronavirus pandemic and its consequences are being actively discussed on social media. However, not all social media posts are truthful. Many of them spread fake news that cause panic among readers, misinform people and thus exacerbate the effect of the pandemic. In this paper, we present our results at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in English. In particular, we propose our approach using the transformer-based ensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used, the ways of text preprocessing and adding extra data. As a result, our best model achieved the weighted F1-score of 98.69 on the test set (the first place in the leaderboard) of this shared task that attracted 166 submitted teams in total.},
	urldate = {2021-12-27},
	journal = {arXiv:2012.11967 [cs]},
	author = {Glazkova, Anna and Glazkov, Maksim and Trifonov, Timofey},
	year = {2021},
	note = {arXiv: 2012.11967},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Information Retrieval, 68T50, H.3.3, I.2.7, I.7.m},
	pages = {116--127},
	file = {arXiv Fulltext PDF:files/436/Glazkova et al. - 2021 - g2tmn at Constraint@AAAI2021 Exploiting CT-BERT a.pdf:application/pdf;arXiv.org Snapshot:files/437/2012.html:text/html},
}

@book{molnar_92_nodate,
	title = {9.2 {Local} {Surrogate} ({LIME}) {\textbar} {Interpretable} {Machine} {Learning}},
	url = {https://christophm.github.io/interpretable-ml-book/lime.html},
	abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.},
	urldate = {2022-01-11},
	author = {Molnar, Christoph},
	file = {Snapshot:files/439/lime.html:text/html},
}

@article{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2022-01-13},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv: 1810.04805},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:files/441/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:files/442/1810.html:text/html},
}

@article{doshi-velez_towards_2017,
	title = {Towards {A} {Rigorous} {Science} of {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1702.08608},
	abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
	language = {en},
	urldate = {2022-01-14},
	journal = {arXiv:1702.08608 [cs, stat]},
	author = {Doshi-Velez, Finale and Kim, Been},
	month = mar,
	year = {2017},
	note = {arXiv: 1702.08608},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Doshi-Velez and Kim - 2017 - Towards A Rigorous Science of Interpretable Machin.pdf:files/443/Doshi-Velez and Kim - 2017 - Towards A Rigorous Science of Interpretable Machin.pdf:application/pdf},
}

@article{dalonzo_machine-learning_2021,
	title = {Machine-{Learning} media bias},
	url = {http://arxiv.org/abs/2109.00024},
	abstract = {We present an automated method for measuring media bias. Inferring which newspaper published a given article, based only on the frequencies with which it uses different phrases, leads to a conditional probability distribution whose analysis lets us automatically map newspapers and phrases into a bias space. By analyzing roughly a million articles from roughly a hundred newspapers for bias in dozens of news topics, our method maps newspapers into a two-dimensional bias landscape that agrees well with previous bias classifications based on human judgement. One dimension can be interpreted as traditional left-right bias, the other as establishment bias. This means that although news bias is inherently political, its measurement need not be.},
	urldate = {2022-01-15},
	journal = {arXiv:2109.00024 [cs]},
	author = {D'Alonzo, Samantha and Tegmark, Max},
	month = aug,
	year = {2021},
	note = {arXiv: 2109.00024},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:files/447/D'Alonzo and Tegmark - 2021 - Machine-Learning media bias.pdf:application/pdf;arXiv.org Snapshot:files/448/2109.html:text/html},
}

@misc{noauthor_stargazers_nodate,
	title = {Stargazers · {Mimino666}/langdetect},
	url = {https://github.com/Mimino666/langdetect},
	abstract = {Port of Google's language-detection library to Python. - Stargazers · Mimino666/langdetect},
	language = {en},
	urldate = {2022-01-16},
	journal = {GitHub},
	file = {Snapshot:files/450/wiki.html:text/html},
}

@article{zhao_shap_2021,
	title = {{SHAP} values for {Explaining} {CNN}-based {Text} {Classification} {Models}},
	url = {http://arxiv.org/abs/2008.11825},
	abstract = {Deep neural networks are increasingly used in natural language processing (NLP) models. However, the need to interpret and explain the results from complex algorithms are limiting their widespread adoption in regulated industries such as banking. There has been recent work on interpretability of machine learning algorithms with structured data. But there are only limited techniques for NLP applications where the problem is more challenging due to the size of the vocabulary, high-dimensional nature, and the need to consider textual coherence and language structure. This paper develops a methodology to compute SHAP values for local explainability of CNN-based text classification models. The approach is also extended to compute global scores to assess the importance of features. The results are illustrated on sentiment analysis of Amazon Electronic Review data.},
	urldate = {2022-01-21},
	journal = {arXiv:2008.11825 [cs]},
	author = {Zhao, Wei and Joshi, Tarun and Nair, Vijayan N. and Sudjianto, Agus},
	month = jul,
	year = {2021},
	note = {arXiv: 2008.11825},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:files/453/Zhao et al. - 2021 - SHAP values for Explaining CNN-based Text Classifi.pdf:application/pdf;arXiv.org Snapshot:files/454/2008.html:text/html},
}

@article{zafar_more_2021,
	title = {More {Than} {Words}: {Towards} {Better} {Quality} {Interpretations} of {Text} {Classifiers}},
	shorttitle = {More {Than} {Words}},
	url = {http://arxiv.org/abs/2112.12444},
	abstract = {The large size and complex decision mechanisms of state-of-the-art text classifiers make it difficult for humans to understand their predictions, leading to a potential lack of trust by the users. These issues have led to the adoption of methods like SHAP and Integrated Gradients to explain classification decisions by assigning importance scores to input tokens. However, prior work, using different randomization tests, has shown that interpretations generated by these methods may not be robust. For instance, models making the same predictions on the test set may still lead to different feature importance rankings. In order to address the lack of robustness of token-based interpretability, we explore explanations at higher semantic levels like sentences. We use computational metrics and human subject studies to compare the quality of sentence-based interpretations against token-based ones. Our experiments show that higher-level feature attributions offer several advantages: 1) they are more robust as measured by the randomization tests, 2) they lead to lower variability when using approximation-based methods like SHAP, and 3) they are more intelligible to humans in situations where the linguistic coherence resides at a higher granularity level. Based on these findings, we show that token-based interpretability, while being a convenient first choice given the input interfaces of the ML models, is not the most effective one in all situations.},
	urldate = {2022-01-21},
	journal = {arXiv:2112.12444 [cs]},
	author = {Zafar, Muhammad Bilal and Schmidt, Philipp and Donini, Michele and Archambeau, Cédric and Biessmann, Felix and Das, Sanjiv Ranjan and Kenthapadi, Krishnaram},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.12444},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:files/456/Zafar et al. - 2021 - More Than Words Towards Better Quality Interpreta.pdf:application/pdf;arXiv.org Snapshot:files/457/2112.html:text/html},
}

@article{kokalj_bert_nodate,
	title = {{BERT} meets {Shapley}: {Extending} {SHAP} {Explanations} to {Transformer}-based {Classifiers}},
	abstract = {Transformer-based neural networks offer very good classiﬁcation performance across a wide range of domains, but do not provide explanations of their predictions. While several explanation methods, including SHAP, address the problem of interpreting deep learning models, they are not adapted to operate on stateof-the-art transformer-based neural networks such as BERT. Another shortcoming of these methods is that their visualization of explanations in the form of lists of most relevant words does not take into account the sequential and structurally dependent nature of text. This paper proposes the TransSHAP method that adapts SHAP to transformer models including BERT-based text classiﬁers. It advances SHAP visualizations by showing explanations in a sequential manner, assessed by human evaluators as competitive to state-of-the-art solutions.},
	language = {en},
	author = {Kokalj, Enja and Škrlj, Blaž and Lavrač, Nada and Pollak, Senja and Robnik-Šikonja, Marko},
	pages = {6},
	file = {Kokalj et al. - BERT meets Shapley Extending SHAP Explanations to.pdf:files/458/Kokalj et al. - BERT meets Shapley Extending SHAP Explanations to.pdf:application/pdf},
}

@article{muller_covid-twitter-bert_2020,
	title = {{COVID}-{Twitter}-{BERT}: {A} {Natural} {Language} {Processing} {Model} to {Analyse} {COVID}-19 {Content} on {Twitter}},
	shorttitle = {{COVID}-{Twitter}-{BERT}},
	url = {http://arxiv.org/abs/2005.07503},
	abstract = {In this work, we release COVID-Twitter-BERT (CT-BERT), a transformer-based model, pretrained on a large corpus of Twitter messages on the topic of COVID-19. Our model shows a 10-30\% marginal improvement compared to its base model, BERT-Large, on five different classification datasets. The largest improvements are on the target domain. Pretrained transformer models, such as CT-BERT, are trained on a specific target domain and can be used for a wide variety of natural language processing tasks, including classification, question-answering and chatbots. CT-BERT is optimised to be used on COVID-19 content, in particular social media posts from Twitter.},
	urldate = {2022-01-27},
	journal = {arXiv:2005.07503 [cs]},
	author = {Müller, Martin and Salathé, Marcel and Kummervold, Per E.},
	month = may,
	year = {2020},
	note = {arXiv: 2005.07503},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
	file = {arXiv Fulltext PDF:files/461/Müller et al. - 2020 - COVID-Twitter-BERT A Natural Language Processing .pdf:application/pdf;arXiv.org Snapshot:files/462/2005.html:text/html},
}

@inproceedings{nguyen_bertweet_2020,
	address = {Online},
	title = {{BERTweet}: {A} pre-trained language model for {English} {Tweets}},
	shorttitle = {{BERTweet}},
	url = {https://aclanthology.org/2020.emnlp-demos.2},
	doi = {10.18653/v1/2020.emnlp-demos.2},
	abstract = {We present BERTweet, the first public large-scale pre-trained language model for English Tweets. Our BERTweet, having the same architecture as BERT-base (Devlin et al., 2019), is trained using the RoBERTa pre-training procedure (Liu et al., 2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base and XLM-R-base (Conneau et al., 2020), producing better performance results than the previous state-of-the-art models on three Tweet NLP tasks: Part-of-speech tagging, Named-entity recognition and text classification. We release BERTweet under the MIT License to facilitate future research and applications on Tweet data. Our BERTweet is available at https://github.com/VinAIResearch/BERTweet},
	urldate = {2022-01-27},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Nguyen, Dat Quoc and Vu, Thanh and Tuan Nguyen, Anh},
	year = {2020},
	pages = {9--14},
	file = {Full Text PDF:files/464/Nguyen et al. - 2020 - BERTweet A pre-trained language model for English.pdf:application/pdf},
}

@article{huang_mcxai_2022,
	title = {{McXai}: {Local} model-agnostic explanation as two games},
	shorttitle = {{McXai}},
	url = {http://arxiv.org/abs/2201.01044},
	abstract = {To this day, a variety of approaches for providing local interpretability of black-box machine learning models have been introduced. Unfortunately, all of these methods suffer from one or more of the following deficiencies: They are either difficult to understand themselves, they work on a per-feature basis and ignore the dependencies between features and/or they only focus on those features asserting the decision made by the model. To address these points, this work introduces a reinforcement learning-based approach called Monte Carlo tree search for eXplainable Artificial Intelligent (McXai) to explain the decisions of any black-box classification model (classifier). Our method leverages Monte Carlo tree search and models the process of generating explanations as two games. In one game, the reward is maximized by finding feature sets that support the decision of the classifier, while in the second game, finding feature sets leading to alternative decisions maximizes the reward. The result is a human friendly representation as a tree structure, in which each node represents a set of features to be studied with smaller explanations at the top of the tree. Our experiments show, that the features found by our method are more informative with respect to classifications than those found by classical approaches like LIME and SHAP. Furthermore, by also identifying misleading features, our approach is able to guide towards improved robustness of the black-box model in many situations.},
	urldate = {2022-01-29},
	journal = {arXiv:2201.01044 [cs]},
	author = {Huang, Yiran and Schaal, Nicole and Hefenbrock, Michael and Zhou, Yexu and Riedel, Till and Fang, Likun and Beigl, Michael},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.01044},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:files/467/Huang et al. - 2022 - McXai Local model-agnostic explanation as two gam.pdf:application/pdf;arXiv.org Snapshot:files/468/2201.html:text/html},
}

@article{ribeiro_model-agnostic_2016,
	title = {Model-{Agnostic} {Interpretability} of {Machine} {Learning}},
	url = {http://arxiv.org/abs/1606.05386},
	abstract = {Understanding why machine learning models behave the way they do empowers both system designers and end-users in many ways: in model selection, feature engineering, in order to trust and act upon the predictions, and in more intuitive user interfaces. Thus, interpretability has become a vital concern in machine learning, and work in the area of interpretable models has found renewed interest. In some applications, such models are as accurate as non-interpretable ones, and thus are preferred for their transparency. Even when they are not accurate, they may still be preferred when interpretability is of paramount importance. However, restricting machine learning to interpretable models is often a severe limitation. In this paper we argue for explaining machine learning predictions using model-agnostic approaches. By treating the machine learning models as black-box functions, these approaches provide crucial flexibility in the choice of models, explanations, and representations, improving debugging, comparison, and interfaces for a variety of users and models. We also outline the main challenges for such methods, and review a recently-introduced model-agnostic explanation approach (LIME) that addresses these challenges.},
	urldate = {2022-01-29},
	journal = {arXiv:1606.05386 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.05386},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:files/471/Ribeiro et al. - 2016 - Model-Agnostic Interpretability of Machine Learnin.pdf:application/pdf;arXiv.org Snapshot:files/472/1606.html:text/html},
}

@article{sanh_distilbert_2020,
	title = {{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter},
	shorttitle = {{DistilBERT}, a distilled version of {BERT}},
	url = {http://arxiv.org/abs/1910.01108},
	abstract = {As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.},
	urldate = {2022-01-30},
	journal = {arXiv:1910.01108 [cs]},
	author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
	month = feb,
	year = {2020},
	note = {arXiv: 1910.01108},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:files/475/Sanh et al. - 2020 - DistilBERT, a distilled version of BERT smaller, .pdf:application/pdf;arXiv.org Snapshot:files/476/1910.html:text/html},
}

@article{liu_roberta_2019,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
	url = {http://arxiv.org/abs/1907.11692},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	urldate = {2022-01-30},
	journal = {arXiv:1907.11692 [cs]},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.11692},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:files/478/Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf:application/pdf;arXiv.org Snapshot:files/479/1907.html:text/html},
}
